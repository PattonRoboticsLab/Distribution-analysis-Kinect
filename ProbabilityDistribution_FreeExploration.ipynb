{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a818b4ee-fddc-4311-8856-631457c15d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import pyvista as pv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from matplotlib.colors import Normalize, LinearSegmentedColormap\n",
    "import matplotlib.cm as cm\n",
    "import networkx as nx\n",
    "import plotly as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.colors as pc\n",
    "import kaleido\n",
    "import pingouin as pg\n",
    "from scipy.stats import rayleigh, skew, kurtosis, pearsonr, genhyperbolic, laplace, spearmanr, ttest_ind\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import find_peaks, savgol_filter, welch, butter, filtfilt, freqz\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy import stats\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools\n",
    "import os\n",
    "import fnmatch\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ab8aa-acf2-4046-8b30-03dfed9b367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass_filter(data):\n",
    "    cutoff = 6\n",
    "    fs = 30\n",
    "    order = 5\n",
    "    nyq = 0.5 * fs\n",
    "    nml_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, nml_cutoff, btype='low', analog=False)\n",
    "    data_filtered = filtfilt(b, a, data)\n",
    "    return data_filtered\n",
    "\n",
    "def filterPositionData(df, center, right, subject):\n",
    "    #print(np.min(df['Wrist_X']))\n",
    "    #print(np.min(df['Wrist_Y']))\n",
    "    #print(np.max(df['Wrist_Z']))\n",
    "    joint_columns = [col for col in df.columns]\n",
    "    for col in joint_columns:\n",
    "        df[col] = butter_lowpass_filter(df[col].values)\n",
    "    \n",
    "    activityWrist = df[['Wrist_X', 'Wrist_Y', 'Wrist_Z']].values  # Just use wrist data to eliminate outliers - most noisy probably\n",
    "\n",
    "    distances = np.linalg.norm(activityWrist, axis=1)  # Create vector of distances to center\n",
    "    filtered_distances = distances[~np.isnan(distances)] # get rid of nan distances\n",
    "\n",
    "\n",
    "    #get height from clinical files spreadsheet\n",
    "    if subject[0] == 's':\n",
    "        heightWeight_df = pd.read_csv('/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/ClinicalFiles/ExoNETPhase0_Heightweight_DATA_LABELS_2024_06_11_1650.csv')\n",
    "    else:\n",
    "        heightWeight_df = pd.read_csv('/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/ClinicalFiles/ExoNETPhase1-Heightweight_DATA_LABELS_2024_06_11_1654.csv')\n",
    "    \n",
    "    subject_Height = heightWeight_df[heightWeight_df['Record ID'].str.lower() == subject.lower()]['Height (inches)'] * 0.0254\n",
    "    subject_Height = subject_Height.values[0]\n",
    "    max_arm_length = subject_Height * 0.5 #based on DA winter's arm segment lengths (0.186, 10.146, 0.108 = 0.44 + wiggle room)\n",
    "    #print('Max Arm Length', max_arm_length)\n",
    "\n",
    "    #build a new array with only the values where distance is less than max arm length\n",
    "    filtered_distances = np.array(filtered_distances)\n",
    "    print(\"before distance filter\", df.shape)\n",
    "    df_filtered = df[filtered_distances < max_arm_length]\n",
    "    print(\"after distance filter\", df_filtered.shape)\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "# Function to check if a point is inside a pyramid\n",
    "def is_inside_pyramid(point, pyramid_vertices, pyramid_number, pyramid_forceList, point_number, forces, IdxByPyramid, radius):\n",
    "    # Check if the point is inside the pyramid using the cross and dot product product \n",
    "    v0, v1, v2, v3 = pyramid_vertices #v0 is the apex, v1,v2,v3 are base vertices\n",
    "    side_vectors = [v1 - v0, v2 - v0, v3 - v0]\n",
    "    point_vector = point - v0\n",
    "\n",
    "    cross1 = np.cross(side_vectors[0], side_vectors[1])\n",
    "    cross2 = np.cross(side_vectors[1], side_vectors[2])\n",
    "    cross3 = np.cross(side_vectors[2], side_vectors[0])\n",
    "    \n",
    "    #check if these normal vectors point inwards, change if they do\n",
    "    if np.dot(cross1, v3 - v0) < 0: cross1 = -cross1\n",
    "    if np.dot(cross2, v1 - v0) < 0: cross2 = -cross2\n",
    "    if np.dot(cross3, v2 - v0) < 0: cross3 = -cross3\n",
    "        \n",
    "    #compute dot products for each: if direction is same between point_vector and cross vector pointing in, point is in the zone\n",
    "    dot1 = np.dot(point_vector, cross1)\n",
    "    dot2 = np.dot(point_vector, cross2)\n",
    "    dot3 = np.dot(point_vector, cross3)\n",
    "    \n",
    "\n",
    "    if dot1 < 0 or dot2 < 0 or dot3 < 0:\n",
    "        return False\n",
    "    else:\n",
    "        if point_number < (len(forces) - 1):\n",
    "            distance_fromShoulder = np.linalg.norm(point_vector)\n",
    "            if distance_fromShoulder < (radius/2):\n",
    "                pyramid_forceList[pyramid_number].append(forces[point_number-1])\n",
    "                IdxByPyramid[pyramid_number].append(point_number)\n",
    "            else:\n",
    "                pyramid_forceList[pyramid_number+20].append(forces[point_number-1])\n",
    "                IdxByPyramid[pyramid_number+20].append(point_number)\n",
    "        return True\n",
    "    \n",
    "    \n",
    "def plot_icosahedron(unique_pyramids, points_in_pyramid, wristMotionOnly, subject):\n",
    "    fig = plt.figure(figsize=(10, 10), dpi=600)\n",
    "    colors = generate_colors(points_in_pyramid)\n",
    "    # Plot for the anterior view\n",
    "    r=1\n",
    "    transparency = 0.7\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    plot_view(ax1, unique_pyramids, colors, r, transparency, elev=88, azim=270)\n",
    "\n",
    "    #posterior is positiveZ\n",
    "    #anterior is negativeZ\n",
    "    negative_z = wristMotionOnly[wristMotionOnly[:,2] < 0]\n",
    "    print(negative_z.shape)\n",
    "    non_negative_z = wristMotionOnly[wristMotionOnly[:,2] >= 0]\n",
    "    print(non_negative_z.shape)\n",
    "\n",
    "    # Add scatter plot for the anterior view\n",
    "    ax1.scatter(non_negative_z[:, 0], non_negative_z[:, 1], non_negative_z[:, 2], color='black', s=0.1)  # Adjust color and size as needed\n",
    "\n",
    "    # Plot for the posterior view\n",
    "    r += 1\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "    plot_view(ax2, unique_pyramids, colors, r, transparency, elev=-88, azim=90)\n",
    "    #add scatter plot for posterior view\n",
    "    ax2.scatter(negative_z[:, 0], negative_z[:, 1], negative_z[:, 2], color='black', s=0.1)  # Adjust color and size as needed\n",
    "\n",
    "\n",
    "    #Save figure in desired path\n",
    "    filepath\n",
    "    directoryFigs = '/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/FiguresCollection/'\n",
    "    Figs_filename = f'IcosahedronPlot_{subject}'\n",
    "    filepathFigs = os.path.join(directoryFigs, Figs_filename)\n",
    "    plt.savefig(filepathFigs, dpi=1600, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_view(ax, unique_pyramids, colors, r, transparency, elev, azim):\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "   # Define the faces of the icosahedron using unique_pyramids\n",
    "    negative_faces = slice(8,18)\n",
    "    faces = [pyramid[1:] for pyramid in unique_pyramids]\n",
    "    #faces = [pyramid[1:] for pyramid in unique_pyramids]\n",
    "\n",
    "    #Adjusting colors based r, if it anterior or posterior\n",
    "    modified_colors = []\n",
    "    linewidths = []\n",
    "    for i, color in enumerate(colors):\n",
    "        if i in range(negative_faces.start, negative_faces.stop):  # This checks if the index is within negative_faces\n",
    "            if r > 1:\n",
    "                alpha = transparency\n",
    "                linewidth = 1 #Change to 0 for individual subject \n",
    "            else:  # Set alpha to 1 if r > 1 and face is in anterior view\n",
    "                alpha = 0\n",
    "                linewidth = 1\n",
    "        else:\n",
    "            if r > 1:\n",
    "                alpha = 0 \n",
    "                linewidth = 1\n",
    "            else:  # Set alpha to 0 if r > 1 and face is not in anterior view\n",
    "                alpha = transparency\n",
    "                linewidth = 1\n",
    "        modified_colors.append((*color[:3], alpha))\n",
    "        linewidths.append(linewidth)\n",
    "    \n",
    "    poly3d = Poly3DCollection(faces, facecolors=modified_colors, edgecolors='k', linewidths=linewidths)\n",
    "    ax.add_collection3d(poly3d)\n",
    "\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.auto_scale_xyz([-1.05, 0.95], [-0.82, 1.22], [0.76, 2.76])\n",
    "        \n",
    "def generate_colors(points_in_pyramid, point_in_pyramid2=None):\n",
    "    if point_in_pyramid2 is None:\n",
    "    # normalize the values, adjust colorscale accordingly\n",
    "        if np.isscalar(points_in_pyramid):\n",
    "            max_abs = 10\n",
    "            norm_value = points_in_pyramid / max_abs  # Scale the single value\n",
    "            color = [plt.cm.Reds(norm_value) if points_in_pyramid >= 0 else plt.cm.Blues(-norm_value)]\n",
    "            return color  # Return the single color as a list\n",
    "        else:\n",
    "            max_abs = np.max(np.abs(points_in_pyramid))\n",
    "            norm = Normalize(vmin=0, vmax=max_abs)\n",
    "            norm_values = [norm(point) for point in points_in_pyramid]\n",
    "            # Red for positive, blue for negative time stroke vs neurotypical\n",
    "            colors = [plt.cm.Reds(norm(point)) if point >= 0 else plt.cm.Blues(-norm(point)) for point in points_in_pyramid]\n",
    "    else:\n",
    "        max_abs = max(max(abs(num) for num in points_in_pyramid), max(abs(num) for num in point_in_pyramid2))\n",
    "        norm = Normalize(vmin=0, vmax=max_abs)\n",
    "        norm_values = [norm(point) for point in points_in_pyramid]\n",
    "        # Red for positive, blue for negative time stroke vs neurotypical\n",
    "        colors = [plt.cm.Reds(norm(point)) if point >= 0 else plt.cm.Blues(-norm(point)) for point in points_in_pyramid]\n",
    "        \n",
    "    return colors\n",
    "\n",
    "\n",
    "def fixing_bin_center(data, n_bins, center, right):\n",
    "    x = data[:, :3]  # assuming data is a pandas DataFrame\n",
    "    #print(x.shape)\n",
    "\n",
    "    #Previous method does not differentiate the stroke vs neurotypical group bc limited ROM is not highlighted. Instead, find max diff as x-axis\n",
    "    distances = np.linalg.norm(x, axis=1)  # Create vector of distances to center\n",
    "    #print(distances)\n",
    "    filtered_distances = distances[~np.isnan(distances)]\n",
    "    furthest_distance = np.max(filtered_distances)\n",
    "    #print('furthest_distance')\n",
    "    #print(furthest_distance)\n",
    "    #Define the furthest distance away as arm length and make a cube around the shoulder joint\n",
    "    mins = np.array([-furthest_distance, -furthest_distance, -furthest_distance])\n",
    "    ranges = np.array([2*furthest_distance, 2*furthest_distance, 2*furthest_distance])\n",
    "\n",
    "    N, n_dim = x.shape\n",
    "    if N <= 2:\n",
    "        print(\"X: >2 rows.\")\n",
    "        return\n",
    "    \n",
    "    #print(f\"\\n Sorting ({N} points, {n_dim} dimensions, {n_bins} Bins)...\")\n",
    "    xb = np.full(x.shape, np.nan)  # NaN array like MATLAB NaN*X\n",
    "\n",
    "    bin_limits = np.zeros((n_bins + 1, n_dim))\n",
    "    bin_centers = np.zeros((n_bins, n_dim))\n",
    "\n",
    "    for dim in range(n_dim):\n",
    "        min_val = mins[dim]\n",
    "        range_val = ranges[dim]\n",
    "        #fraction of range\n",
    "        x_fract_of_range = (x[:, dim] - min_val) / (range_val + np.finfo(float).eps)\n",
    "        \n",
    "        # transform to bin space and make integer by flooring to the min value in each bin\n",
    "        xb[:, dim] = np.floor(n_bins * x_fract_of_range).astype(int)\n",
    "        \n",
    "        # Bin limits and centers\n",
    "        bin_limits[:, dim] = min_val + range_val / n_bins * np.arange(n_bins + 1)\n",
    "        bin_centers[:, dim] = (bin_limits[:-1, dim] + bin_limits[1:, dim]) / 2\n",
    "    \n",
    "    return xb, bin_limits, bin_centers\n",
    "\n",
    "def linearRegression(fmue_scores, dependentVar, zone, fig, title, color_count):\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#1b9e77', '#aec7e8', '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5', '#c49c94', '#f7b6d2', '#c7c7c7', '#dbdb8d', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#1b9e77', '#aec7e8', '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5', '#c49c94', '#f7b6d2', '#c7c7c7', '#dbdb8d']\n",
    "    if len(dependentVar) > 10:\n",
    "        fmue_scores = np.array(fmue_scores)\n",
    "        dependentVar = np.array(dependentVar)\n",
    "        regressionValues = LinearRegression().fit(fmue_scores.reshape(-1, 1), dependentVar)\n",
    "        slope = regressionValues.coef_[0]\n",
    "        percent_pred_Values = regressionValues.predict(fmue_scores.reshape(-1, 1))\n",
    "        r2 = r2_score(dependentVar, percent_pred_Values)\n",
    "        r = spearmanr(fmue_scores, dependentVar)\n",
    "        p_val = r.pvalue\n",
    "        print(f\"{title} Zone {zone + 1}: Slope={slope}, R^2={r2}, R={r}\")\n",
    "        if p_val <= 0.01:\n",
    "            fig.add_trace(go.Scatter(x=fmue_scores, y=dependentVar, mode='markers', marker=dict(color=colors[color_count]), name=f'Zone {zone+1}'))\n",
    "            fig.add_trace(go.Scatter(x=fmue_scores, y=percent_pred_Values, mode='lines', line=dict(color=colors[color_count]), showlegend=False))\n",
    "\n",
    "def jointAnalysis(df):\n",
    "    #reference vectors:\n",
    "    shoulderElbowvectorX = df['Elbow_X'] - df['Shoulder_X']\n",
    "    shoulderElbowvectorY = df['Elbow_Y'] - df['Shoulder_Y']\n",
    "    shoulderElbowvectorZ = df['Elbow_Z'] - df['Shoulder_Z']\n",
    "    shoulderElbowvector = np.column_stack((shoulderElbowvectorX, shoulderElbowvectorY, shoulderElbowvectorZ))\n",
    "    shoulderElbowvector /= np.linalg.norm(shoulderElbowvector)\n",
    "\n",
    "    elbowWristvectorX = df['Wrist_X'] - df['Elbow_X']\n",
    "    elbowWristvectorY = df['Wrist_Y'] - df['Elbow_Y']\n",
    "    elbowWristvectorZ = df['Wrist_Z'] - df['Elbow_Z']\n",
    "    elbowWristvector = np.column_stack((elbowWristvectorX, elbowWristvectorY, elbowWristvectorZ))\n",
    "    elbowWristvector /= np.linalg.norm(elbowWristvector)\n",
    "\n",
    "    shoulder2shouldervectorX = df['ShoulderRef_X'] - df['ShoulderOther_X']\n",
    "    shoulder2shouldervectorY = df['ShoulderRef_Y'] - df['ShoulderOther_Y']\n",
    "    shoulder2shouldervectorZ = df['ShoulderRef_Z'] - df['ShoulderOther_Z']\n",
    "    shoulder2shouldervector = np.column_stack((shoulder2shouldervectorX, shoulder2shouldervectorY, shoulder2shouldervectorZ))\n",
    "    shoulder2shouldervector /= np.linalg.norm(shoulder2shouldervector)\n",
    "\n",
    "    spineVectorX = df['SpineShoulder_X'] - df['SpineBase_X']\n",
    "    spineVectorY = df['SpineShoulder_Y'] - df['SpineBase_Y']\n",
    "    spineVectorZ = df['SpineShoulder_Z'] - df['SpineBase_Z']\n",
    "    spineVector = np.column_stack((spineVectorX, spineVectorY, spineVectorZ))\n",
    "    spineVector /= np.linalg.norm(spineVector)\n",
    "\n",
    "    #rotation matrices\n",
    "    rotation_matrix = np.vstack([shoulder2shouldervector, spineVector, np.cross(shoulder2shouldervector, spineVector)]).T\n",
    "    \n",
    "    #calculate Euler angles (ZYX order for intrinsic rotations)\n",
    "    rotation = R.from_matrix(rotation_matrix)\n",
    "    euler_angles = rotation.as_euler('zyx', degrees=True)\n",
    "    \n",
    "    #print(\"Shoulder Flexion Angle (Euler ZYX):\", euler_angles)\n",
    "\n",
    "    #Shoulder Flexion\n",
    "    flexion_angle = euler_angles[1]  # Y-axis rotation (Flexion)\n",
    "\n",
    "    #Shoulder Abduction\n",
    "    abduction_angle = euler_angles[2] # Z-axis rotation (Abduction)\n",
    "\n",
    "    #Elbow Flexion -  just use 3D points\n",
    "    ElbowAngles = np.zeros(df.shape[0])\n",
    "    for row in range(df.shape[0]):\n",
    "        dot_Elbow = np.dot(shoulderElbowvector[row], elbowWristvector[row])\n",
    "        magnitude_ElbShoul = np.linalg.norm(elbowShouldervector[row])\n",
    "        magnitude_ElbWrist = np.linalg.norm(elbowWristvector[row])\n",
    "        cos_theta = dot_Elbow / (magnitude_ElbShoul * magnitude_ElbWrist)\n",
    "        cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
    "        ElbowAngles[row] = np.degrees(np.arccos(cos_theta))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def calc_jointangles(df):\n",
    "    # Initialize lists to store vectors and angles\n",
    "    shoulderElbowvectorX = df['Elbow_X'] - df['Shoulder_X']\n",
    "    shoulderElbowvectorY = df['Elbow_Y'] - df['Shoulder_Y']\n",
    "    shoulderElbowvectorZ = df['Elbow_Z'] - df['Shoulder_Z']\n",
    "    shoulderElbowvector = np.column_stack((shoulderElbowvectorX, shoulderElbowvectorY, shoulderElbowvectorZ))\n",
    "    shoulderElbowvector /= np.linalg.norm(shoulderElbowvector)\n",
    "\n",
    "    elbowWristvectorX = df['Wrist_X'] - df['Elbow_X']\n",
    "    elbowWristvectorY = df['Wrist_Y'] - df['Elbow_Y']\n",
    "    elbowWristvectorZ = df['Wrist_Z'] - df['Elbow_Z']\n",
    "    elbowWristvector = np.column_stack((elbowWristvectorX, elbowWristvectorY, elbowWristvectorZ))\n",
    "    elbowWristvector /= np.linalg.norm(elbowWristvector)\n",
    "\n",
    "    wristHandvectorX = df['Hand_X'] - df['Wrist_X']\n",
    "    wristHandvectorY = df['Hand_Y'] - df['Wrist_Y']\n",
    "    wristHandvectorZ = df['Hand_Z'] - df['Wrist_Z']\n",
    "    wristHandvector = np.column_stack((wristHandvectorX, wristHandvectorY, wristHandvectorZ))\n",
    "    wristHandvector /= np.linalg.norm(wristHandvector)\n",
    "\n",
    "    #transverse vector - used for calculating flexion\n",
    "    shoulder2shouldervectorX = df['ShoulderRef_X'] - df['ShoulderOther_X']\n",
    "    shoulder2shouldervectorY = df['ShoulderRef_Y'] - df['ShoulderOther_Y']\n",
    "    shoulder2shouldervectorZ = df['ShoulderRef_Z'] - df['ShoulderOther_Z']\n",
    "    shoulder2shouldervector = np.column_stack((shoulder2shouldervectorX, shoulder2shouldervectorY, shoulder2shouldervectorZ))\n",
    "    shoulder2shouldervector /= np.linalg.norm(shoulder2shouldervector)\n",
    "\n",
    "    #vertical vector - used for calculating abduction\n",
    "    hip2shouldervectorX = df['ShoulderRef_X'] - df['Hip_X']\n",
    "    hip2shouldervectorY = df['ShoulderRef_Y'] - df['Hip_Y']\n",
    "    hip2shouldervectorZ = df['ShoulderRef_Z'] - df['Hip_Z']\n",
    "    hip2shouldervector = np.column_stack((hip2shouldervectorX, hip2shouldervectorY, hip2shouldervectorZ))\n",
    "    hip2shouldervector /= np.linalg.norm(hip2shouldervector)\n",
    "    \n",
    "    # Initialize an array to store joint angles\n",
    "    joint_angles = np.zeros((len(shoulderElbowvectorX), 4))\n",
    "\n",
    "    # Shoulder abduction/adduction - angle between hipshoulder and elbowshoulder\n",
    "    for i in range(len(shoulderElbowvectorX)):\n",
    "        cross_product = np.cross(hip2shouldervector[i], shoulderElbowvector[i])\n",
    "        dot_product = np.dot(hip2shouldervector[i], shoulderElbowvector[i])\n",
    "        joint_angles[i, 0] = np.degrees(np.arctan2(np.linalg.norm(cross_product), dot_product))\n",
    "\n",
    "    # Shoulder flexion/extension - angle between spineshoulder and elbowshoulder\n",
    "        cross_product = np.cross(shoulder2shouldervector[i], shoulderElbowvector[i])\n",
    "        dot_product = np.dot(shoulder2shouldervector[i], shoulderElbowvector[i])\n",
    "        joint_angles[i, 1] = np.degrees(np.arctan2(np.linalg.norm(cross_product), dot_product))\n",
    "\n",
    "    # Elbow flexion/extension - angle between elbowwrist and elbowshoulder\n",
    "        cross_product = np.cross(shoulderElbowvector[i], elbowWristvector[i])\n",
    "        dot_product = np.dot(shoulderElbowvector[i], elbowWristvector[i])\n",
    "        joint_angles[i, 2] = np.degrees(np.arctan2(np.linalg.norm(cross_product), dot_product))\n",
    "\n",
    "    #Wrist flexion/extension - angle between wristHand and elbowWrist\n",
    "        cross_product = np.cross(elbowWristvector[i], wristHandvector[i])\n",
    "        dot_product = np.dot(elbowWristvector[i], wristHandvector[i])\n",
    "        joint_angles[i, 3] = np.degrees(np.arctan2(np.linalg.norm(cross_product), dot_product))\n",
    "\n",
    "    #title = \"Shoulder Flexion v. Elbow Flexion\"\n",
    "    #fig = px.scatter(x=joint_angles[:, 1], y=joint_angles[:, 2])\n",
    "    #fig.update_layout(\n",
    "    #    title=title,\n",
    "    #    xaxis=dict(title='Shoulder Flexion', range=[0, 180]),\n",
    "    #    yaxis=dict(title='Elbow Flexion', range = [0, 180]),\n",
    "    #    width=600,\n",
    "    #    height=600,\n",
    "    #    plot_bgcolor='white',\n",
    "    #    showlegend=False,\n",
    "    #    margin=dict(l=50, r=50, b=50, t=50),\n",
    "    #)\n",
    "    #fig.show()\n",
    "\n",
    "    #title =  \"Shoulder Abduction v Elbow Flexion\"\n",
    "    #fig = px.scatter(x=joint_angles[:, 0], y=joint_angles[:, 2])\n",
    "    #fig.update_layout(\n",
    "    #    title=title,\n",
    "    #    xaxis=dict(title='Shoulder Abduction', range = [0, 180]),\n",
    "    #    yaxis=dict(title='Elbow Flexion', range = [0, 180]),\n",
    "    #    width=600,\n",
    "    #    height=600,\n",
    "    #    plot_bgcolor='white',\n",
    "    #    showlegend=False,\n",
    "    #    margin=dict(l=50, r=50, b=50, t=50),\n",
    "    #)\n",
    "    #fig.show()\n",
    "\n",
    "    #title =  \"Shoulder Flexion v Shoulder Abduction\"\n",
    "    #fig = px.scatter(x=joint_angles[:, 1], y=joint_angles[:, 0])\n",
    "    #fig.update_layout(\n",
    "    #    title=title,\n",
    "    #    xaxis=dict(title='Shoulder Flexion', range = [0, 180]),\n",
    "    #    yaxis=dict(title='Shoulder Abduction', range = [0, 180]),\n",
    "    #    width=600,\n",
    "    #    height=600,\n",
    "    #    plot_bgcolor='white',\n",
    "    #    showlegend=False,\n",
    "    #    margin=dict(l=50, r=50, b=50, t=50),\n",
    "    #)\n",
    "    #fig.show()\n",
    "\n",
    "    #title = \"Elbow Flexion v Wrist Flexion\"\n",
    "    #fig = px.scatter(x=joint_angles[:, 2], y=joint_angles[:, 3])\n",
    "    #fig.update_layout(\n",
    "    #    title=title,\n",
    "    #    xaxis=dict(title='Elbow Flexion'),\n",
    "    #    yaxis=dict(title='Wrist Flexion'),\n",
    "    #    width=600,\n",
    "    #    height=600,\n",
    "    #    plot_bgcolor='white',\n",
    "    #    showlegend=False,\n",
    "    #    margin=dict(l=50, r=50, b=50, t=50),\n",
    "    #)\n",
    "    #fig.show()\n",
    "\n",
    "    #3D plot tests: shoulder abduction v. elbow flexion v. shoulder flexion\n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter3d(\n",
    "            x=joint_angles[:, 0],\n",
    "            y=joint_angles[:, 2],\n",
    "            z=joint_angles[:, 1], \n",
    "            mode='markers',\n",
    "            marker=dict(size=2, color='blue'),\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"3D scatter of the shoulder and elbow angles\",\n",
    "        scene=dict(\n",
    "            xaxis=dict(title='Shoulder Abduction'),\n",
    "            yaxis=dict(title='Elbow Flexion'),\n",
    "            zaxis=dict(title='Shoulder Flexion'),\n",
    "        ),\n",
    "        width=800,\n",
    "        height=800,\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "    return joint_angles\n",
    "\n",
    "\n",
    "def jointAngleCalculations(df, right):\n",
    "    #Merge points - tired of all this right and left stuff\n",
    "\n",
    "    #initialize jointAngles_summary\n",
    "    JointAngle_summary = [[] for _ in range(9)]\n",
    "    JointCorrelation_summary = [[] for _ in range(3)]\n",
    "    #check angles shoulder -  3 points - shoulder_right, hip_right, elbow_right\n",
    "    ShoulderAngles = np.zeros(df.shape[0])\n",
    "    shoulderHipvectorX = df['Hip_X'] -  df['Shoulder_X']\n",
    "    shoulderHipvectorY = df['Hip_Y'] -  df['Shoulder_Y']\n",
    "    shoulderHipvectorZ = df['Hip_Z'] -  df['Shoulder_Z']\n",
    "    shoulderHipvector = np.column_stack((shoulderHipvectorX, shoulderHipvectorY, shoulderHipvectorZ))\n",
    "    \n",
    "    shoulderElbowvectorX = df['Elbow_X'] - df['Shoulder_X']\n",
    "    shoulderElbowvectorY = df['Elbow_Y'] - df['Shoulder_Y']\n",
    "    shoulderElbowvectorZ = df['Elbow_Z'] - df['Shoulder_Z']\n",
    "    shoulderElbowvector = np.column_stack((shoulderElbowvectorX, shoulderElbowvectorY, shoulderElbowvectorZ))\n",
    "    \n",
    "    for row in range(df.shape[0]):\n",
    "        dot_Shoulder = np.dot(shoulderHipvector[row], shoulderElbowvector[row])\n",
    "        magnitude_SholHip = np.linalg.norm(shoulderHipvector[row])\n",
    "        magnitude_SholElb = np.linalg.norm(shoulderElbowvector[row])\n",
    "        cos_theta = dot_Shoulder / (magnitude_SholHip * magnitude_SholElb)\n",
    "        cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
    "        ShoulderAngles[row] = np.degrees(np.arccos(cos_theta))\n",
    "\n",
    "    median = np.median(ShoulderAngles)\n",
    "    mode = stats.mode(ShoulderAngles)[0][0]  # mode returns a ModeResult object\n",
    "    data_range = np.ptp(ShoulderAngles)  # ptp = peak to peak (max - min)\n",
    "    variance = np.var(ShoulderAngles, ddof=1)  # ddof=1 for sample variance\n",
    "    std_dev = np.std(ShoulderAngles, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    iqr = stats.iqr(ShoulderAngles)\n",
    "    skewness = stats.skew(ShoulderAngles)\n",
    "    kurt = stats.kurtosis(ShoulderAngles)\n",
    "    #print(f'Shoulder Angle - mean: {mean}, median: {median}, mode: {mode}, range: {data_range}, variance: {variance}, std_dev: {std_dev}, iqr: {iqr}, skewness: {skewness}, kurtosis: {kurt}')\n",
    "    ShoulderAngleSummary = [median, mode, data_range, variance, std_dev, iqr, skewness, kurt]\n",
    "    #plt.hist(ShoulderAngles, bins='auto', edgecolor='black')\n",
    "    #plt.title('Shoulder Histogram of Angles (degrees)')\n",
    "    #plt.xlabel('Angle (degrees)')\n",
    "    #plt.ylabel('Frequency')\n",
    "    #plt.show()\n",
    "    JointAngle_summary[0] = ShoulderAngleSummary\n",
    "    #print(f'Range Shoulder Angle: {[np.min(ShoulderAngles), np.max(ShoulderAngles)]}')\n",
    "        \n",
    "    #Check angles elbow - 3 points - elbow_right, shoulder_right, wrist_right\n",
    "    ElbowAngles = np.zeros(df.shape[0])\n",
    "    elbowShouldervectorX = df['Shoulder_X'] - df['Elbow_X']\n",
    "    elbowShouldervectorY = df['Shoulder_Y'] - df['Elbow_Y']\n",
    "    elbowShouldervectorZ = df['Shoulder_Z'] - df['Elbow_Z']\n",
    "    elbowShouldervector = np.column_stack((elbowShouldervectorX, elbowShouldervectorY, elbowShouldervectorZ))\n",
    "    \n",
    "    elbowWristvectorX = df['Wrist_X'] - df['Elbow_X']\n",
    "    elbowWristvectorY = df['Wrist_Y'] - df['Elbow_Y']\n",
    "    elbowWristvectorZ = df['Wrist_Z'] - df['Elbow_Z']\n",
    "    elbowWristvector = np.column_stack((elbowWristvectorX, elbowWristvectorY, elbowWristvectorZ))\n",
    "    \n",
    "    for row in range(df.shape[0]):\n",
    "        dot_Elbow = np.dot(elbowShouldervector[row], elbowWristvector[row])\n",
    "        magnitude_ElbShoul = np.linalg.norm(elbowShouldervector[row])\n",
    "        magnitude_ElbWrist = np.linalg.norm(elbowWristvector[row])\n",
    "        cos_theta = dot_Elbow / (magnitude_ElbShoul * magnitude_ElbWrist)\n",
    "        cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
    "        ElbowAngles[row] = np.degrees(np.arccos(cos_theta))\n",
    "    \n",
    "    median = np.median(ElbowAngles)\n",
    "    mode = stats.mode(ElbowAngles)[0][0]  # mode returns a ModeResult object\n",
    "    data_range = np.ptp(ElbowAngles)  # ptp = peak to peak (max - min)\n",
    "    variance = np.var(ElbowAngles, ddof=1)  # ddof=1 for sample variance\n",
    "    std_dev = np.std(ElbowAngles, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    iqr = stats.iqr(ElbowAngles)\n",
    "    skewness = stats.skew(ElbowAngles)\n",
    "    kurt = stats.kurtosis(ElbowAngles)\n",
    "    #print(f'Elbow Angle - mean: {mean}, median: {median}, mode: {mode}, range: {data_range}, variance: {variance}, std_dev: {std_dev}, iqr: {iqr}, skewness: {skewness}, kurtosis: {kurt}')\n",
    "    ElbowAngleSummary = [median, mode, data_range, variance, std_dev, iqr, skewness, kurt]\n",
    "    #plt.hist(ElbowAngles, bins='auto', edgecolor='black')\n",
    "    #plt.title('Elbow Histogram of Angles (degrees)')\n",
    "    #plt.xlabel('Angle (degrees)')\n",
    "    #plt.ylabel('Frequency')\n",
    "    #plt.show()\n",
    "    JointAngle_summary[1] = ElbowAngleSummary\n",
    "    #print(f'Range Elbow Angle: {[np.min(ElbowAngles), np.max(ElbowAngles)]}')\n",
    "    \n",
    "    #check angles wrist -  3points - wrist_right, elbow_right, hand_right\n",
    "    WristAngles = np.zeros(df.shape[0])\n",
    "    wristElbowvectorX = df['Elbow_X'] - df['Wrist_X']\n",
    "    wristElbowvectorY = df['Elbow_Y'] - df['Wrist_Y']\n",
    "    wristElbowvectorZ = df['Elbow_Z'] - df['Wrist_Z']\n",
    "    wristElbowvector = np.column_stack((wristElbowvectorX, wristElbowvectorY, wristElbowvectorZ))\n",
    "    \n",
    "    wristHandvectorX = df['Hand_X'] - df['Wrist_X']\n",
    "    wristHandvectorY = df['Hand_Y'] - df['Wrist_Y']\n",
    "    wristHandvectorZ = df['Hand_Z'] - df['Wrist_Z']\n",
    "    wristHandvector = np.column_stack((wristHandvectorX, wristHandvectorY, wristHandvectorZ))\n",
    "    \n",
    "    for row in range(df.shape[0]):\n",
    "        dot_Wrist = np.dot(wristElbowvector[row], wristHandvector[row])\n",
    "        magnitude_WriElb = np.linalg.norm(wristElbowvector[row])\n",
    "        magnitude_WriHan = np.linalg.norm(wristHandvector[row])\n",
    "        cos_theta = dot_Wrist / (magnitude_WriElb * magnitude_WriHan)\n",
    "        cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
    "        WristAngles[row] = np.degrees(np.arccos(cos_theta))\n",
    "    \n",
    "    median = np.median(WristAngles)\n",
    "    mode = stats.mode(WristAngles)[0][0]  # mode returns a ModeResult object\n",
    "    data_range = np.ptp(WristAngles)  # ptp = peak to peak (max - min)\n",
    "    variance = np.var(WristAngles, ddof=1)  # ddof=1 for sample variance\n",
    "    std_dev = np.std(WristAngles, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    iqr = stats.iqr(WristAngles)\n",
    "    skewness = stats.skew(WristAngles)\n",
    "    kurt = stats.kurtosis(WristAngles)\n",
    "    #print(f'Wrist Angle - mean: {mean}, median: {median}, mode: {mode}, range: {data_range}, variance: {variance}, std_dev: {std_dev}, iqr: {iqr}, skewness: {skewness}, kurtosis: {kurt}')\n",
    "    WristAngleSummary = [median, mode, data_range, variance, std_dev, iqr, skewness, kurt]\n",
    "    #plt.hist(WristAngles, bins='auto', edgecolor='black')\n",
    "    #plt.title('Wrist Histogram of Angles (degrees)')\n",
    "    #plt.xlabel('Angle (degrees)')\n",
    "    #plt.ylabel('Frequency')\n",
    "    #plt.show()\n",
    "    JointAngle_summary[2] = WristAngleSummary\n",
    "    #print(f'Range Wrist Angle: {[np.min(WristAngles), np.max(WristAngles)]}')\n",
    "\n",
    "    #Jointangle correlations & velocity and acceleration calculations\n",
    "    fps=30\n",
    "    #Find the angular velocities and accelerations\n",
    "    Vel_ShoulderAngle = np.diff(ShoulderAngles) * fps\n",
    "    Vel_ElbowAngle = np.diff(ElbowAngles) * fps\n",
    "    Vel_WristAngle = np.diff(WristAngles) * fps\n",
    "    Acc_ShoulderAngle = np.diff(Vel_ShoulderAngle) * fps\n",
    "    Acc_ElbowAngle = np.diff(Vel_ElbowAngle) * fps\n",
    "    Acc_WristAngle = np.diff(Vel_WristAngle) * fps\n",
    "\n",
    "    #Do the correlation math\n",
    "    r_shoulElb, p_val = pearsonr(ShoulderAngles, ElbowAngles)\n",
    "    r_elbWri, p_val = pearsonr(ElbowAngles, WristAngles)\n",
    "    r_shoulWri, p_val = pearsonr(ShoulderAngles, WristAngles)\n",
    "\n",
    "    r_Vel_shoulElb, p_val = pearsonr(Vel_ShoulderAngle, Vel_ElbowAngle)\n",
    "    r_Vel_elbWri, p_val = pearsonr(Vel_ElbowAngle, Vel_WristAngle)\n",
    "    r_Vel_shoulWri, p_val = pearsonr(Vel_ShoulderAngle, Vel_WristAngle)\n",
    "\n",
    "    r_Acc_shoulElb, p_val = pearsonr(Acc_ShoulderAngle, Acc_ElbowAngle)\n",
    "    r_Acc_elbWri, p_val = pearsonr(Acc_ElbowAngle, Acc_WristAngle)\n",
    "    r_Acc_shoulWri, p_val = pearsonr(Acc_ShoulderAngle, Acc_WristAngle)\n",
    "\n",
    "    Displacement_summary = [r_shoulElb, r_elbWri, r_shoulWri]\n",
    "    Velocity_summary = [r_Vel_shoulElb, r_Vel_elbWri, r_Vel_shoulWri]\n",
    "    Acceleration_summary = [r_Acc_shoulElb, r_Acc_elbWri, r_Acc_shoulWri]\n",
    "    JointCorrelation_summary[0] = Displacement_summary\n",
    "    JointCorrelation_summary[1] = Velocity_summary\n",
    "    JointCorrelation_summary[2] = Acceleration_summary\n",
    "\n",
    "    #summary details of angular velocity - Shoulder and Elbow\n",
    "    median = np.median(Vel_ShoulderAngle)\n",
    "    mode = stats.mode(Vel_ShoulderAngle)[0][0]  # mode returns a ModeResult object\n",
    "    data_range = np.ptp(Vel_ShoulderAngle)  # ptp = peak to peak (max - min)\n",
    "    variance = np.var(Vel_ShoulderAngle, ddof=1)  # ddof=1 for sample variance\n",
    "    std_dev = np.std(Vel_ShoulderAngle, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    iqr = stats.iqr(Vel_ShoulderAngle)\n",
    "    skewness = stats.skew(Vel_ShoulderAngle)\n",
    "    kurt = stats.kurtosis(Vel_ShoulderAngle)\n",
    "    AngVel_ShoulSummary = [median, mode, data_range, variance, std_dev, iqr, skewness, kurt]\n",
    "    JointAngle_summary[3] = AngVel_ShoulSummary\n",
    "\n",
    "    median = np.median(Vel_ElbowAngle)\n",
    "    mode = stats.mode(Vel_ElbowAngle)[0][0]  # mode returns a ModeResult object\n",
    "    data_range = np.ptp(Vel_ElbowAngle)  # ptp = peak to peak (max - min)\n",
    "    variance = np.var(Vel_ElbowAngle, ddof=1)  # ddof=1 for sample variance\n",
    "    std_dev = np.std(Vel_ElbowAngle, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    iqr = stats.iqr(Vel_ElbowAngle)\n",
    "    skewness = stats.skew(Vel_ElbowAngle)\n",
    "    kurt = stats.kurtosis(Vel_ElbowAngle)\n",
    "    AngVel_ElbowSummary = [median, mode, data_range, variance, std_dev, iqr, skewness, kurt]\n",
    "    JointAngle_summary[4] = AngVel_ElbowSummary\n",
    "\n",
    "    median = np.median(Vel_WristAngle)\n",
    "    mode = stats.mode(Vel_WristAngle)[0][0]  # mode returns a ModeResult object\n",
    "    data_range = np.ptp(Vel_WristAngle)  # ptp = peak to peak (max - min)\n",
    "    variance = np.var(Vel_WristAngle, ddof=1)  # ddof=1 for sample variance\n",
    "    std_dev = np.std(Vel_WristAngle, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    iqr = stats.iqr(Vel_WristAngle)\n",
    "    skewness = stats.skew(Vel_WristAngle)\n",
    "    kurt = stats.kurtosis(Vel_WristAngle)\n",
    "    AngVel_WristSummary = [median, mode, data_range, variance, std_dev, iqr, skewness, kurt]\n",
    "    JointAngle_summary[5] = AngVel_WristSummary\n",
    "\n",
    "    #Angular Acceleration\n",
    "    median = np.median(Acc_ShoulderAngle)\n",
    "    mode = stats.mode(Acc_ShoulderAngle)[0][0]  # mode returns a ModeResult object\n",
    "    data_range = np.ptp(Acc_ShoulderAngle)  # ptp = peak to peak (max - min)\n",
    "    variance = np.var(Acc_ShoulderAngle, ddof=1)  # ddof=1 for sample variance\n",
    "    std_dev = np.std(Acc_ShoulderAngle, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    iqr = stats.iqr(Acc_ShoulderAngle)\n",
    "    skewness = stats.skew(Acc_ShoulderAngle)\n",
    "    kurt = stats.kurtosis(Acc_ShoulderAngle)\n",
    "    AngAcc_ShoulSummary = [median, mode, data_range, variance, std_dev, iqr, skewness, kurt]\n",
    "    JointAngle_summary[6] = AngAcc_ShoulSummary\n",
    "\n",
    "    median = np.median(Acc_ElbowAngle)\n",
    "    mode = stats.mode(Acc_ElbowAngle)[0][0]  # mode returns a ModeResult object\n",
    "    data_range = np.ptp(Acc_ElbowAngle)  # ptp = peak to peak (max - min)\n",
    "    variance = np.var(Acc_ElbowAngle, ddof=1)  # ddof=1 for sample variance\n",
    "    std_dev = np.std(Acc_ElbowAngle, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    iqr = stats.iqr(Acc_ElbowAngle)\n",
    "    skewness = stats.skew(Acc_ElbowAngle)\n",
    "    kurt = stats.kurtosis(Acc_ElbowAngle)\n",
    "    AngAcc_ElbowSummary = [median, mode, data_range, variance, std_dev, iqr, skewness, kurt]\n",
    "    JointAngle_summary[7] = AngAcc_ElbowSummary\n",
    "\n",
    "    median = np.median(Acc_WristAngle)\n",
    "    mode = stats.mode(Acc_WristAngle)[0][0]  # mode returns a ModeResult object\n",
    "    data_range = np.ptp(Acc_WristAngle)  # ptp = peak to peak (max - min)\n",
    "    variance = np.var(Acc_WristAngle, ddof=1)  # ddof=1 for sample variance\n",
    "    std_dev = np.std(Acc_WristAngle, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    iqr = stats.iqr(Acc_WristAngle)\n",
    "    skewness = stats.skew(Acc_WristAngle)\n",
    "    kurt = stats.kurtosis(Acc_WristAngle)\n",
    "    AngAcc_WristSummary = [median, mode, data_range, variance, std_dev, iqr, skewness, kurt]\n",
    "    JointAngle_summary[8] = AngAcc_WristSummary\n",
    "\n",
    "        #ElbowAngles = filterAngles(ElbowAngles)\n",
    "        #plt.hist(ElbowAngles, bins=55, edgecolor='black')\n",
    "        #plt.xlim(0, 180)\n",
    "        #plt.title('Elbow Angles Distribution')\n",
    "        #plt.xlabel('Deg')\n",
    "        #plt.ylabel('Frequency')\n",
    "        #plt.show()\n",
    "\n",
    "        #Vel_ElbowAngle = filterAngles(Vel_ElbowAngle)\n",
    "        #plt.hist(Vel_ElbowAngle, bins=55, edgecolor='black')\n",
    "        #plt.title('Elbow Anglular Velocity Distribution')\n",
    "        #plt.xlabel('Deg/s')\n",
    "        #plt.ylabel('Frequency')\n",
    "        #plt.show()\n",
    "        \n",
    "        #Acc_ElbowAngle = filterAngles(Acc_ElbowAngle)\n",
    "        #plt.hist(Acc_ElbowAngle, bins=55, edgecolor='black')\n",
    "        #plt.title('Elbow Anglular Acceleration Distribution')\n",
    "        #plt.xlabel('Deg/s^2')\n",
    "        #plt.ylabel('Frequency')\n",
    "        #plt.show()\n",
    "    \n",
    "    return JointCorrelation_summary, JointAngle_summary, ElbowAngles, ShoulderAngles, WristAngles\n",
    "\n",
    "def distCalculations(zone_values):\n",
    "    summaryList = []\n",
    "    if len(zone_values) > 4:\n",
    "        zone_values = np.round(zone_values, decimals=4)\n",
    "        median = np.median(zone_values)\n",
    "        mode = stats.mode(zone_values)[0][0]  # mode returns a ModeResult object\n",
    "        data_range = np.ptp(zone_values)  # ptp = peak to peak (max - min)\n",
    "        variance = np.var(zone_values, ddof=1)  # ddof=1 for sample variance\n",
    "        std_dev = np.std(zone_values, ddof=1)  # ddof=1 for sample standard deviation\n",
    "        iqr = stats.iqr(zone_values)\n",
    "        skewness = skew(zone_values)\n",
    "            #Leptokurtosis\n",
    "        kurt = kurtosis(zone_values, fisher=False)\n",
    "        summaryList = [median, mode, data_range, std_dev, iqr, skewness, kurt, len(zone_values)]\n",
    "    return summaryList\n",
    "\n",
    "def shape_modeling(df, right, subject, jointAngle_list, stats_summary, stats_icosahedron, stats_rectilinear, stats_vel_icos, stats_acc_icos, stats_forceavg_icosahedron, stats_forceavg_rectilinear, stats_jointAngavg_icosahedron, stats_synergy_icosahedron, stats_mvt_icosahedron, cumData):\n",
    "    if right == 1:\n",
    "        shoulder_cols = ['ShoulderRight_X', 'ShoulderRight_Y', 'ShoulderRight_Z']\n",
    "        wrist_cols = ['WristRight_X', 'WristRight_Y', 'WristRight_Z']\n",
    "    else:\n",
    "        shoulder_cols = ['ShoulderLeft_X', 'ShoulderLeft_Y', 'ShoulderLeft_Z']\n",
    "        wrist_cols = ['WristLeft_X', 'WristLeft_Y', 'WristLeft_Z']\n",
    "    \n",
    "    \n",
    "    center = df[shoulder_cols].loc[:100, :].mean()\n",
    "    center.astype(np.int64)\n",
    "    df = df.drop(df.index[-1])\n",
    "    if right == 1:\n",
    "        df['Wrist_X'] = df['WristRight_X'] - center['ShoulderRight_X']\n",
    "        df['Wrist_Y'] = df['WristRight_Y'] - center['ShoulderRight_Y']\n",
    "        df['Wrist_Z'] = df['WristRight_Z'] - center['ShoulderRight_Z']\n",
    "        df['Hip_X'] = df['HipRight_X'] - center['ShoulderRight_X']\n",
    "        df['Hip_Y'] = df['HipRight_Y'] - center['ShoulderRight_Y']\n",
    "        df['Hip_Z'] = df['HipRight_Z'] - center['ShoulderRight_Z']\n",
    "        df['Elbow_X'] = df['ElbowRight_X'] - center['ShoulderRight_X']\n",
    "        df['Elbow_Y'] = df['ElbowRight_Y'] - center['ShoulderRight_Y']\n",
    "        df['Elbow_Z'] = df['ElbowRight_Z'] - center['ShoulderRight_Z']\n",
    "        df['Hand_X'] = df['HandRight_X'] - center['ShoulderRight_X']\n",
    "        df['Hand_Y'] = df['HandRight_Y'] - center['ShoulderRight_Y']\n",
    "        df['Hand_Z'] = df['HandRight_Z'] - center['ShoulderRight_Z']\n",
    "        df['Shoulder_X'] = df['ShoulderRight_X'] - center['ShoulderRight_X']\n",
    "        df['Shoulder_Y'] = df['ShoulderRight_Y'] - center['ShoulderRight_Y']\n",
    "        df['Shoulder_Z'] = df['ShoulderRight_Z'] - center['ShoulderRight_Z']\n",
    "        df['Thumb_X'] = df['ThumbRight_X'] - center['ShoulderRight_X']\n",
    "        df['Thumb_Y'] = df['ThumbRight_Y'] - center['ShoulderRight_Y']\n",
    "        df['Thumb_Z'] = df['ThumbRight_Z'] - center['ShoulderRight_Z']\n",
    "        df['ShoulderRef_X'] = df['Shoulder_X']\n",
    "        df['ShoulderRef_Y'] = df['Shoulder_Y']\n",
    "        df['ShoulderRef_Z'] = df['Shoulder_Z']\n",
    "        df['ShoulderOther_X'] = df['ShoulderLeft_X']\n",
    "        df['ShoulderOther_Y'] = df['ShoulderLeft_Y']\n",
    "        df['ShoulderOther_Z'] = df['ShoulderLeft_Z']\n",
    "        center['ShoulderRight_X'] -= center['ShoulderRight_X']\n",
    "        center['ShoulderRight_Y'] -= center['ShoulderRight_Y']\n",
    "        center['ShoulderRight_Z'] -= center['ShoulderRight_Z']\n",
    "    else:\n",
    "        df['Wrist_X'] = -(df['WristLeft_X'] - center['ShoulderLeft_X'])\n",
    "        df['Wrist_Y'] = df['WristLeft_Y'] - center['ShoulderLeft_Y']\n",
    "        df['Wrist_Z'] = df['WristLeft_Z'] - center['ShoulderLeft_Z']\n",
    "        df['Hip_X'] = -(df['HipLeft_X'] - center['ShoulderLeft_X'])\n",
    "        df['Hip_Y'] = df['HipLeft_Y'] - center['ShoulderLeft_Y']\n",
    "        df['Hip_Z'] = df['HipLeft_Z'] - center['ShoulderLeft_Z']\n",
    "        df['Elbow_X'] = -(df['ElbowLeft_X'] - center['ShoulderLeft_X'])\n",
    "        df['Elbow_Y'] = df['ElbowLeft_Y'] - center['ShoulderLeft_Y']\n",
    "        df['Elbow_Z'] = df['ElbowLeft_Z'] - center['ShoulderLeft_Z']\n",
    "        df['Hand_X'] = -(df['HandLeft_X'] - center['ShoulderLeft_X'])\n",
    "        df['Hand_Y'] = df['HandLeft_Y'] - center['ShoulderLeft_Y']\n",
    "        df['Hand_Z'] = df['HandLeft_Z'] - center['ShoulderLeft_Z']\n",
    "        df['Shoulder_X'] = -(df['ShoulderLeft_X'] - center['ShoulderLeft_X'])\n",
    "        df['Shoulder_Y'] = df['ShoulderLeft_Y'] - center['ShoulderLeft_Y']\n",
    "        df['Shoulder_Z'] = df['ShoulderLeft_Z'] - center['ShoulderLeft_Z']\n",
    "        df['Thumb_X'] = -(df['ThumbLeft_X'] - center['ShoulderLeft_X'])\n",
    "        df['Thumb_Y'] = df['ThumbLeft_Y'] - center['ShoulderLeft_Y']\n",
    "        df['Thumb_Z'] = df['ThumbLeft_Z'] - center['ShoulderLeft_Z']\n",
    "        df['ShoulderRef_X'] = df['Shoulder_X']\n",
    "        df['ShoulderRef_Y'] = df['Shoulder_Y']\n",
    "        df['ShoulderRef_Z'] = df['Shoulder_Z']\n",
    "        df['ShoulderOther_X'] = df['ShoulderRight_X']\n",
    "        df['ShoulderOther_Y'] = df['ShoulderRight_Y']\n",
    "        df['ShoulderOther_Z'] = df['ShoulderRight_Z']\n",
    "        center['ShoulderLeft_X'] -= center['ShoulderLeft_X']\n",
    "        center['ShoulderLeft_Y'] -= center['ShoulderLeft_Y']\n",
    "        center['ShoulderLeft_Z'] -= center['ShoulderLeft_Z']\n",
    "        #call filter95 function to cut >95% percentile distances from shoulder\n",
    "\n",
    "    fs = 30\n",
    "    trim_for_abstract = fs * 120 #trim the first 2 minutes of the data\n",
    "    df = df.loc[:trim_for_abstract, :]\n",
    "    \n",
    "    #print(f'Filter95 Check {df.shape}')\n",
    "    df = filterPositionData(df, center, right, subject)\n",
    "    #df = df_filtered \n",
    "    \n",
    "    #fig2 = px.scatter_3d(df, x=\"Wrist_X\", y=\"Wrist_Y\", z=\"Wrist_Z\")\n",
    "    #fig2.update_layout(height = 500, width = 500)\n",
    "    #fig2.update_traces(marker = dict(size = 2))\n",
    "    #fig2.show()\n",
    "    \n",
    "    #fig3 = px.scatter_3d(df_filtered, x=\"Wrist_X\", y=\"Wrist_Y\", z=\"Wrist_Z\")\n",
    "    #fig3.update_layout(height = 500, width = 500)\n",
    "    #fig3.update_traces(marker = dict(size = 2))\n",
    "    \n",
    "    #fig3.add_trace(go.Scatter3d(\n",
    "    #    x=[0],  # Origin x\n",
    "    #    y=[0],  # Origin y\n",
    "    #    z=[0],\n",
    "    #    mode='markers',  # Show marker only\n",
    "    #    marker=dict(color='red', size=5),  # Red color and size of the marker\n",
    "    #    name='Origin'\n",
    "    #))\n",
    "    \n",
    "    #fig3.show()\n",
    "    \n",
    "    #testing distribution as spherical - Calculate radius for Icosahedron vertices\n",
    "    vectorX = df['Wrist_X'] \n",
    "    vectorY = df['Wrist_Y']\n",
    "    vectorZ = df['Wrist_Z'] \n",
    "    vectors=np.column_stack((vectorX[:-1], vectorY[:-1], vectorZ[:-1]))\n",
    "    vectors_normalized = vectors / np.linalg.norm(vectors, axis=1)[:, np.newaxis]\n",
    "    azimuthal_angles = np.arctan2(vectors_normalized[:, 1], vectors_normalized[:, 0])\n",
    "    polar_angles = np.arctan2(vectors_normalized[:, 2], np.sqrt(vectors_normalized[:, 0] ** 2 + vectors_normalized[:, 1] ** 2))\n",
    "    \n",
    "    #find the radius of the spherical distribution\n",
    "    magnitudes = np.linalg.norm(vectors, axis=1)\n",
    "    largest_magnitude = np.max(magnitudes)\n",
    "    avg_magnitude = np.mean(magnitudes)\n",
    "    med_magnitude = np.median(magnitudes)\n",
    "    radius = largest_magnitude\n",
    "    #print(f'radius: {radius}')\n",
    "    \n",
    "    # golden ratio\n",
    "    phi = (1 + np.sqrt(5)) / 2\n",
    "    \n",
    "    # vertices of a unit icosahedron\n",
    "    icosahedron_vertices = np.array([\n",
    "        [0, 1, phi],\n",
    "        [0, -1, phi],\n",
    "        [0, 1, -phi],\n",
    "        [0, -1, -phi],\n",
    "        [1, phi, 0],\n",
    "        [-1, phi, 0],\n",
    "        [1, -phi, 0],\n",
    "        [-1, -phi, 0],\n",
    "        [phi, 0, 1],\n",
    "        [-phi, 0, 1],\n",
    "        [phi, 0, -1],\n",
    "        [-phi, 0, -1]\n",
    "    ])\n",
    "    \n",
    "    # scaling by the largest magnitude of vector_normalized (from prev calc)\n",
    "    factorNorm = radius / phi\n",
    "    icosahedron_vertices *= factorNorm\n",
    "    \n",
    "    #fig2.add_trace(go.Scatter3d(\n",
    "    #    x=icosahedron_vertices[:, 0],\n",
    "    #    y=icosahedron_vertices[:, 1],\n",
    "    #    z=icosahedron_vertices[:, 2],\n",
    "    #    mode='markers',\n",
    "    #    marker=dict(size=4, color='black')\n",
    "    #))\n",
    "    \n",
    "    # show the figure\n",
    "    #fig2.show()\n",
    "\n",
    "    #test 1: find correct unique_pyramids\n",
    "    # Assuming icosahedron_vertices and center are defined\n",
    "    center = np.array([0, 0, 0])\n",
    "    distances = cdist(icosahedron_vertices, icosahedron_vertices)\n",
    "\n",
    "    # Find the 5 nearest neighbors for each vertex (excluding itself)\n",
    "    # argsort sorts distances, so [:, 1:6] skips the first column (distance to itself) and selects the next 5 nearest neighbors.\n",
    "    nearest_neighbors_indices = np.argsort(distances, axis=1)[:, 1:6]\n",
    "    # Sort nearest neighbors indices for consistent processing\n",
    "    nearest_neighbors_indices = np.sort(nearest_neighbors_indices, axis=1)\n",
    "    \n",
    "    unique_pyramids_set = set()\n",
    "    for vertex_idx, neighbors_idx in enumerate(nearest_neighbors_indices):\n",
    "        vertex = icosahedron_vertices[vertex_idx]\n",
    "        neighbors = icosahedron_vertices[neighbors_idx]\n",
    "    \n",
    "        # Generate combinations of neighbors\n",
    "        neighbor_combinations = itertools.combinations(neighbors_idx, 2)\n",
    "    \n",
    "        for combination_idx in neighbor_combinations:\n",
    "            combination = icosahedron_vertices[np.array([vertex_idx, *combination_idx])]\n",
    "            combination = combination[np.lexsort(combination.T)]  # Sort vertices of the pyramid\n",
    "    \n",
    "            # Calculate distances\n",
    "            dist_01 = np.linalg.norm(combination[0] - combination[1])\n",
    "            dist_12 = np.linalg.norm(combination[1] - combination[2])\n",
    "            dist_20 = np.linalg.norm(combination[2] - combination[0])\n",
    "            \n",
    "            # Check for equilateral triangle\n",
    "            mean_dist = np.mean([dist_01, dist_12, dist_20])\n",
    "            if np.allclose([dist_01, dist_12, dist_20], mean_dist, atol=1e-6):\n",
    "                # Add sorted combination to the set with the center\n",
    "                sorted_indices = tuple(sorted([vertex_idx, *combination_idx]))\n",
    "                unique_pyramids_set.add(sorted_indices)\n",
    "    \n",
    "    # Convert back to list of pyramids and prepend the center point\n",
    "    unique_pyramids = []\n",
    "    for indices in unique_pyramids_set:\n",
    "        pyramid_vertices = icosahedron_vertices[list(indices)]\n",
    "        pyramid_with_center = np.vstack([center, pyramid_vertices])  # Add center as the apex\n",
    "        unique_pyramids.append(pyramid_with_center)\n",
    "    \n",
    "    # Print the resulting pyramids\n",
    "    #print(\"Unique Pyramids:\")\n",
    "    #for pyramid in unique_pyramids:\n",
    "        #print(pyramid)\n",
    "\n",
    "\n",
    "    wristMotionX = df['Wrist_X']\n",
    "    wristMotionY = df['Wrist_Y']\n",
    "    wristMotionZ = df['Wrist_Z']\n",
    "    wristMotionOnly=np.column_stack((wristMotionX, wristMotionY, wristMotionZ))\n",
    "\n",
    "    #get mass from clinical files spreadsheet\n",
    "    if subject[0] == 's':\n",
    "        heightWeight_df = pd.read_csv('/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/ClinicalFiles/ExoNETPhase0_Heightweight_DATA_LABELS_2024_06_11_1650.csv')\n",
    "    else:\n",
    "        heightWeight_df = pd.read_csv('/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/ClinicalFiles/ExoNETPhase1-Heightweight_DATA_LABELS_2024_06_11_1654.csv')\n",
    "\n",
    "    subject_Height = heightWeight_df[heightWeight_df['Record ID'].str.lower() == subject.lower()]['Height (inches)'] * 0.0254\n",
    "    subject_Height = subject_Height.values[0]\n",
    "    head_position = np.mean(df['Head_Y'])\n",
    "    foot_position = np.mean(df['FootLeft_Y'])\n",
    "    estimated_Height = head_position - foot_position\n",
    "    #Call on heightWeight_df to get the weights and conver to mass (kg)\n",
    "    subject_Mass = heightWeight_df[heightWeight_df['Record ID'].str.lower() == subject.lower()]['Weight (lbs)'] * 0.454 #find weight and convert to mass by dividing gravity\n",
    "    subject_Mass = subject_Mass.values[0]\n",
    "    Arm_mass = 0.05 * subject_Mass\n",
    "    #Calculate velocity, acceleration, force (for now - acceleration enough\n",
    "    vel = np.diff(wristMotionOnly, axis=0) * fs\n",
    "    #print(f'Velocity {vel.shape}')\n",
    "    accel = np.diff(vel, axis=0) * fs\n",
    "    #print(f'Accel {accel.shape}')\n",
    "    jerk = np.diff(accel, axis=0) * fs\n",
    "    #print(f'Jerk {jerk.shape}')\n",
    "    forces = Arm_mass * np.linalg.norm(accel, axis=1) #for now, its just accel magnitude\n",
    "    veloc = np.linalg.norm(vel, axis=1) #magnitude velocity\n",
    "    accel = np.linalg.norm(accel, axis=1) #magnitude acceleration\n",
    "    jerk = np.linalg.norm(jerk, axis=1) #magnitude jerk\n",
    "\n",
    "    #plot movement\n",
    "    #make movingaverage filter\n",
    "    window=5\n",
    "    samp_rate = 30\n",
    "    vel_Xma = np.convolve(vel[:,0], np.ones(window)/window, mode='valid')\n",
    "    vel_Yma = np.convolve(vel[:,1], np.ones(window)/window, mode='valid')\n",
    "    vel_Zma = np.convolve(vel[:,2], np.ones(window)/window, mode='valid')\n",
    "    vel_ma = np.convolve(veloc, np.ones(window)/window, mode='valid')\n",
    "    acc_ma = np.convolve(accel, np.ones(window)/window, mode='valid')\n",
    "    #filter jerk\n",
    "    cutoff = 10\n",
    "    jerk_filtered = butter_lowpass_filter(jerk)\n",
    "    jerk_ma = np.convolve(jerk, np.ones(window)/window, mode='valid')\n",
    "    #ma_vel_line = go.Scatter(x=np.arange(len(vel_ma)) + window -1, y=vel_ma, mode='lines', name='Velocity')\n",
    "    ma_acc_line = go.Scatter(x=np.arange(len(acc_ma))+window-1, y=acc_ma, mode='lines', name='Acceleration')\n",
    "    ma_jerk_line = go.Scatter(x=np.arange(len(jerk_ma))+window-1, y=jerk_ma, mode='lines', name='Jerk')\n",
    "    #identify movements\n",
    "    trough_indices, _ = find_peaks(-jerk_ma, distance=window, prominence=600)  #do i need to adjust this index based on smookthening??\n",
    "    adj_trough_indices = trough_indices + (window - 1)\n",
    "    #print(f'Troughs: {len(adj_trough_indices)}')\n",
    "    #print(adj_trough_indices)\n",
    "    #figvel = go.Figure()\n",
    "    #figvel.add_trace(go.Scatter(x=np.arange(len(vel_Xma)) + window -1, y=vel_Xma, mode='lines', name='Vel X', marker=dict(color='red')))\n",
    "    #figvel.add_trace(go.Scatter(x=np.arange(len(vel_Yma)) + window -1, y=vel_Yma, mode='lines', name='Vel Y', marker=dict(color='blue')))\n",
    "    #figvel.add_trace(go.Scatter(x=np.arange(len(vel_Zma)) + window -1, y=vel_Zma, mode='lines', name='Vel Z', marker=dict(color='green')))\n",
    "    #figvel.add_trace(go.Scatter(x=np.arange(len(vel_ma)) + window -1, y=vel_ma, mode='lines', name='Vel mag', marker=dict(color='black')))\n",
    "    ##figacc = go.Figure(data=[ma_acc_line])\n",
    "    #figjerk = go.Figure(data=[ma_jerk_line])\n",
    "    #figjerk.add_trace(go.Scatter(x=adj_trough_indices, y=jerk_ma[trough_indices], mode='markers', marker=dict(symbol='star',size=5, color='red')))\n",
    "    #layout\n",
    "    #figvel.update_layout(title='Velocity', xaxis_title='frames', yaxis_title='m/s')\n",
    "    #figacc.update_layout(title='Acceleration', xaxis_title='frames', yaxis_title='m/(s^2)')\n",
    "    #figjerk.update_layout(title='Jerk', xaxis_title='frames', yaxis_title='m/(s^3)')\n",
    "    #figvel.show()\n",
    "    #figacc.show()\n",
    "    #figjerk.show()\n",
    "\n",
    "    # count the number of points in each pyramidal region\n",
    "    pyramid_forceList = [[] for _ in range(40)]\n",
    "    IdxByPyramid = [[] for _ in range(40)]\n",
    "    pyramid_number = -1\n",
    "\n",
    "    #JointAngle_listoflists = jointAngleCalculations(refined_df, right)\n",
    "    #points_in_pyramid = [(pyramid_number := pyramid_number + 1, sum(is_inside_pyramid(point, pyramid, pyramid_number, pyramid_forceList, point_number, forces) for point in wristMotionOnly)) for pyramid in unique_pyramids]\n",
    "    #FIGURE OUT HOW TO MAKE XB version here?\n",
    "    points_in_pyramid = [\n",
    "        (\n",
    "            pyramid_number := pyramid_number + 1,\n",
    "            sum(\n",
    "                (is_inside_pyramid(point, pyramid, pyramid_number, pyramid_forceList, point_number, forces, IdxByPyramid, radius)) \n",
    "                for point_number, point in enumerate(wristMotionOnly, start=1)\n",
    "            )\n",
    "        )\n",
    "        for pyramid in unique_pyramids\n",
    "    ]\n",
    "    #parse and categorize the listoflists for joint angles, velocity, and acceleration\n",
    "    SynergyTotalSummary, TotalDataAngle_summary, ElbowAngles, ShoulderAngles, WristAngles = jointAngleCalculations(df, right)\n",
    "    #rint(f'Synergy Correlation Summary: {subject} {SynergyTotalSummary}')\n",
    "\n",
    "    #print(\"JOINT ANGLE Jialin method\")\n",
    "    jointangles = calc_jointangles(df)\n",
    "    jointAngle_list.append(jointangles)\n",
    "\n",
    "    JointAngle_listoflists = []\n",
    "    Synergy_listoflists = []\n",
    "    Vel_byzone = []\n",
    "    Accel_byzone = []\n",
    "    points_in_pyramid40 = [[] for _ in range(40)]\n",
    "    for i in range(40):\n",
    "        idx = IdxByPyramid[i]\n",
    "        points_in_pyramid40[i] = len(idx)\n",
    "        valid_idx = [i for i in idx if i in df.index] #some are dropped as outliers previously - in python, it leaves the index value empty\n",
    "        invalid_idx = [i for i in idx if i not in df.index]\n",
    "        idx = valid_idx\n",
    "        refined_df = df.loc[idx, :]\n",
    "        vel_curr = veloc[idx[:-1]]\n",
    "        accel_curr = accel[idx[:-2]]\n",
    "        vel_summary = distCalculations(vel_curr)\n",
    "        accel_summary = distCalculations(accel_curr)\n",
    "        \n",
    "        if len(idx) > 4:\n",
    "            print(i)\n",
    "            JointCorrelation_summary, JointAngle_summary, na, na, na = jointAngleCalculations(refined_df, right)\n",
    "        else:\n",
    "            JointAngle_summary = []\n",
    "            JointCorrelation_summary = []\n",
    "        JointAngle_listoflists.append(JointAngle_summary)\n",
    "        Synergy_listoflists.append(JointCorrelation_summary)\n",
    "        Vel_byzone.append(vel_summary)\n",
    "        Accel_byzone.append(accel_summary)\n",
    "        \n",
    "    points_refined_pyramid = [selectedPyramidPoints[1] for selectedPyramidPoints in points_in_pyramid]\n",
    "    points_in_pyramid = points_refined_pyramid\n",
    "    # print the counts\n",
    "    forcedistributions_ListofLists = []\n",
    "    #for i, count in enumerate(points_in_pyramid40, 1):\n",
    "        #print(f\"Pyramid {i}: {count} points inside\")\n",
    "    \n",
    "    for eachPyramidForces in pyramid_forceList:\n",
    "        if len(eachPyramidForces) > 4:\n",
    "            eachPyramidForces = np.round(eachPyramidForces, decimals=5)\n",
    "            median = np.median(eachPyramidForces)\n",
    "            mode = stats.mode(eachPyramidForces)[0][0]  # mode returns a ModeResult object\n",
    "            data_range = np.ptp(eachPyramidForces)  # ptp = peak to peak (max - min)\n",
    "            variance = np.var(eachPyramidForces, ddof=1)  # ddof=1 for sample variance\n",
    "            std_dev = np.std(eachPyramidForces, ddof=1)  # ddof=1 for sample standard deviation\n",
    "            iqr = stats.iqr(eachPyramidForces)\n",
    "            if len(eachPyramidForces) > 4:\n",
    "                force_skewness = skew(eachPyramidForces)\n",
    "                #Leptokurtosis\n",
    "                force_excess_kurtosis = kurtosis(eachPyramidForces, fisher=False)\n",
    "                #Normal\n",
    "                ks_test = stats.kstest(eachPyramidForces, 'norm', args=(np.mean(eachPyramidForces), np.std(eachPyramidForces)))\n",
    "                shapiro_test = stats.shapiro(eachPyramidForces)\n",
    "                force_ks = ks_test.statistic\n",
    "                force_shap = shapiro_test.statistic\n",
    "                expon_stat, p_exp_ks = stats.kstest(eachPyramidForces, 'expon')\n",
    "                lognormal_stat, p_lognormal_sw = stats.shapiro(np.log(eachPyramidForces))\n",
    "            else:\n",
    "                force_skewness = np.nan\n",
    "                force_excess_kurtosis = np.nan\n",
    "                force_ks = np.nan\n",
    "                force_shap = np.nan\n",
    "                expon_stat = np.nan\n",
    "                lognormal_stat = np.nan\n",
    "            \n",
    "            forcedistributions_ListofLists.append([median, mode, data_range, std_dev, iqr, force_skewness, force_excess_kurtosis, len(eachPyramidForces)])\n",
    "        else:\n",
    "            force_skewness = np.nan\n",
    "            force_excess_kurtosis = np.nan\n",
    "            force_ks = np.nan\n",
    "            force_shap = np.nan\n",
    "            expon_stat = np.nan\n",
    "            lognormal_stat = np.nan\n",
    "            forcedistributions_ListofLists.append([])\n",
    "\n",
    "    #MOVEMENT DIVERSITY ANALYSIS\n",
    "    #Find the angular velocities and accelerations\n",
    "    Vel_ShoulderAngle = np.diff(ShoulderAngles) * fs\n",
    "    Vel_ElbowAngle = np.diff(ElbowAngles) * fs\n",
    "    Vel_WristAngle = np.diff(WristAngles) * fs\n",
    "    Acc_ShoulderAngle = np.diff(Vel_ShoulderAngle) * fs\n",
    "    Acc_ElbowAngle = np.diff(Vel_ElbowAngle) * fs\n",
    "    Acc_WristAngle = np.diff(Vel_WristAngle) * fs\n",
    "    zoned_startpts = [[] for i in range(40)]\n",
    "    zoned_endzones = [[] for i in range(40)]\n",
    "    Mvt_linearvelocities = []\n",
    "    Mvt_ShoulAngularVel = []\n",
    "    Mvt_ElbowAngularVel = []\n",
    "    Mvt_WristAngularVel = []\n",
    "    Mvt_linearaccelerations = []\n",
    "    Mvt_ShoulAngularAcc = []\n",
    "    Mvt_ElbowAngularAcc = []\n",
    "    Mvt_WristAngularAcc = []\n",
    "    Mvt_TADshoulder = []\n",
    "    Mvt_NADshoulder = []\n",
    "    Mvt_TADelbow = []\n",
    "    Mvt_NADelbow = []\n",
    "    all_startpts = adj_trough_indices #split by jerk\n",
    "    for s, startpt in enumerate(all_startpts, start=1):\n",
    "        if s < len(all_startpts):\n",
    "            endpt = all_startpts[s] - 1 #find the start and end point for each movement - ignore last one\n",
    "            for i, sublist in enumerate(IdxByPyramid):\n",
    "                if startpt in sublist:\n",
    "                    zoned_startpts[i].append(startpt)\n",
    "                    for j, endzoneList in enumerate(IdxByPyramid, start=1):\n",
    "                        if endpt in endzoneList:\n",
    "                            zoned_endzones[i].append(j)\n",
    "                            break\n",
    "                    break\n",
    "            #calculate the net angular displacement, total angular displacement + ratio of the two per movement\n",
    "            # Calculate total angular displacement\n",
    "            currMvt_ShAng = ShoulderAngles[startpt:endpt]\n",
    "            tad_curr_Shoulder = np.sum(np.abs(np.diff(currMvt_ShAng)))\n",
    "            nad_curr_Shoulder = currMvt_ShAng[-1] - currMvt_ShAng[0]\n",
    "            Mvt_TADshoulder.append(tad_curr_Shoulder)\n",
    "            Mvt_NADshoulder.append(nad_curr_Shoulder)\n",
    "            currMvt_ElbAng = ElbowAngles[startpt:endpt]\n",
    "            tad_curr_Elbow = np.sum(np.abs(np.diff(currMvt_ElbAng)))\n",
    "            nad_curr_Elbow = currMvt_ElbAng[-1] - currMvt_ElbAng[0]\n",
    "            Mvt_TADelbow.append(tad_curr_Elbow)\n",
    "            Mvt_NADelbow.append(nad_curr_Elbow)\n",
    "            #linear accelerations - not using this rn\n",
    "            currMvt_vel = veloc[startpt:endpt]\n",
    "            currMvt_velAvg = np.mean(currMvt_vel)\n",
    "            Mvt_linearvelocities.append(currMvt_velAvg)\n",
    "            currMvt_acc = accel[startpt:endpt]\n",
    "            currMvt_accAvg = np.mean(currMvt_acc)\n",
    "            Mvt_linearaccelerations.append(currMvt_accAvg)\n",
    "            #angular velocities\n",
    "            currMvt_ShAngularVel = Vel_ShoulderAngle[startpt:endpt]\n",
    "            #median shoulder angular vel and acc\n",
    "            if len(currMvt_ShAngularVel) > 5:\n",
    "                currMvt_ShAngVelMed = np.median(currMvt_ShAngularVel)\n",
    "                Mvt_ShoulAngularVel.append(currMvt_ShAngVelMed)\n",
    "                currMvt_ShAngularAcc = Acc_ShoulderAngle[startpt:endpt]\n",
    "                currMvt_ShAngAccMed = np.median(currMvt_ShAngularAcc)\n",
    "                Mvt_ShoulAngularAcc.append(currMvt_ShAngAccMed)\n",
    "            #elbow angular vel and acc\n",
    "            currMvt_ElAngularVel = Vel_ElbowAngle[startpt:endpt]\n",
    "            if len(currMvt_ElAngularVel)> 5:\n",
    "                currMvt_ElAngVelMed = np.median(currMvt_ElAngularVel)\n",
    "                Mvt_ElbowAngularVel.append(currMvt_ElAngVelMed)\n",
    "                currMvt_ElAngularAcc = Acc_ElbowAngle[startpt:endpt]\n",
    "                currMvt_ElAngAccMed = np.median(currMvt_ElAngularAcc)\n",
    "                Mvt_ElbowAngularAcc.append(currMvt_ElAngAccMed)\n",
    "            #wrist angular vel and acc\n",
    "            currMvt_WriAngularVel = Vel_WristAngle[startpt:endpt]\n",
    "            if len(currMvt_WriAngularVel) > 5:\n",
    "                currMvt_WriAngularVelMed = np.median(currMvt_WriAngularVel)\n",
    "                Mvt_WristAngularVel.append(currMvt_WriAngularVelMed)\n",
    "                currMvt_WriAngularAcc = Acc_WristAngle[startpt:endpt]\n",
    "                currMvt_WriAngAccMed = np.median(currMvt_WriAngularAcc)\n",
    "                Mvt_WristAngularAcc.append(currMvt_WriAngAccMed)\n",
    "                \n",
    "    #print('CHECK movement selection')\n",
    "    #print(zoned_startpts)\n",
    "    #print(zoned_endzones)\n",
    "\n",
    "    #plot scatter for overall shoulder and elbow angular velocities and accelerations\n",
    "    #fig = go.Figure(data=go.Scatter(x=np.abs(Vel_ShoulderAngle), y=np.abs(Vel_ElbowAngle), mode='markers'))\n",
    "    #fig.update_layout(title='Shoulder and Elbow Angular Velocities', xaxis_title='Shoulder deg/s', yaxis_title='Elbow deg/s')\n",
    "    #fig.show()\n",
    "\n",
    "    #plot scatter for overall shoulder and elbow angular velocities and accelerations\n",
    "    #fig = go.Figure(data=go.Scatter(x=np.abs(Acc_ShoulderAngle), y=np.abs(Acc_ElbowAngle), mode='markers'))\n",
    "    #fig.update_layout(title='Shoulder and Elbow Angular Accelerations', xaxis_title='Shoulder deg/(s^2)', yaxis_title='Elbow deg/(s^2)')\n",
    "    #fig.show()\n",
    "\n",
    "    #plot scatter of total angular displacement and net angular displacement by movement -underlying synergies?\n",
    "    #x_indices = list(range(len(Mvt_TADshoulder)))\n",
    "    #tad_shoulder = go.Scatter(x=x_indices, y=Mvt_TADshoulder, mode='markers', name='TAD Shoulder', marker=dict(color='blue'))\n",
    "    #nad_shoulder = go.Scatter(x=x_indices, y=Mvt_NADshoulder, mode='markers', name='NAD Shoulder', marker=dict(color='green'))\n",
    "    #fig = go.Figure(data=[tad_shoulder, nad_shoulder])\n",
    "    ##fig.update_layout(title='tad and nad shoulder angles per movement', xaxis_title='Movement #', yaxis_title='Angular Displacement (deg)')\n",
    "    #figfilename = f'{subject}_shoulder_tadnad.png'\n",
    "    #fig.write_image(figfilename)\n",
    "\n",
    "    #x_indices = list(range(len(Mvt_TADelbow)))\n",
    "    #tad_elbow = go.Scatter(x=x_indices, y=Mvt_TADelbow, mode='markers', name='TAD Elbow', marker=dict(color='blue'))\n",
    "    #nad_elbow = go.Scatter(x=x_indices, y=Mvt_NADelbow, mode='markers', name='NAD Elbow', marker=dict(color='green'))\n",
    "    #fig = go.Figure(data=[tad_elbow, nad_elbow])\n",
    "    #fig.update_layout(title='tad and nad elbow angles per movement', xaxis_title='Movement #', yaxis_title='Angular Displacement (deg)')\n",
    "    #figfilename = f'{subject}_elbow_tadnad.png'\n",
    "    #fig.write_image(figfilename)\n",
    "\n",
    "\n",
    "    #Convhull positon data\n",
    "    WristPositionhull = ConvexHull(wristMotionOnly)\n",
    "    #plt.plot(wristMotionOnly[:, 0], wristMotionOnly[:, 1], 'o')\n",
    "    #for simplex in WristPositionhull.simplices:\n",
    "    #    plt.plot(wristMotionOnly[simplex, 0], wristMotionOnly[simplex, 1], 'k-')\n",
    "    #plt.show()\n",
    "    print(f'Convex Hull Wrist Position 3D volume {WristPositionhull.area}')\n",
    "\n",
    "    #adjacency matrix - to show node connections that represent the zones\n",
    "    \n",
    "    ## count the number of points in each pyramidal region\n",
    "    #points_in_pyramid = [sum(is_inside_pyramid(point, pyramid) for point in wristMotionOnly) for pyramid in unique_pyramids]\n",
    "    \n",
    "    # print the counts\n",
    "   # for i, count in enumerate(points_in_pyramid, 1):\n",
    "    #    print(f\"Pyramid {i}: {count} points inside\")\n",
    "    \n",
    "    # call the function to plot the icosahedron\n",
    "    #plot_icosahedron(unique_pyramids, points_in_pyramid, wristMotionOnly, subject)\n",
    "\n",
    "    # Rectilinear modeling - center +/- radius in x,y,z direction - divide each dimension by ndim\n",
    "    n_bins = 3\n",
    "    xb, bin_limits, bin_centers = fixing_bin_center(wristMotionOnly, n_bins, center, right)\n",
    "    #print(bin_centers)\n",
    "    #print(bin_limits)\n",
    "\n",
    "    #convert x,y,z index to rectilinear S,R,C indexing\n",
    "    regFinder = np.full(xb.shape, np.nan)  # NaN array like MATLAB NaN*X\n",
    "    regFinder[:, 2] = 2 - xb[:, 0] #x-column convert to column-column (2-x bc inverted indexing)\n",
    "    regFinder[:, 1] = 2 - xb[:, 1]  #y-column convert to rows-column (2-y bc inverted indexing)\n",
    "    regFinder[:, 0] = 2 - xb[:, 2] #z-column convert to slice-column (2-z bc inverted indexing)\n",
    "    \n",
    "    Nxb, ndim = regFinder.shape\n",
    "    rect_forceList = [[[[] for _ in range(n_bins)] for _ in range(n_bins)] for _ in range(n_bins)]\n",
    "    #Organize list of lists for forces based on regFinder\n",
    "    for l in (range(Nxb - 2)):\n",
    "        currForce_designation = regFinder[l, :]\n",
    "        currForce_designation = [int(i) for i in currForce_designation]\n",
    "        rect_forceList[currForce_designation[0]][currForce_designation[1]][currForce_designation[2]].append(forces[l])\n",
    "    \n",
    "    #Calculate average forces per bin - rectilinear\n",
    "    rect_force_avgs =  [[[[] for _ in range(n_bins)] for _ in range(n_bins)] for _ in range(n_bins)]\n",
    "    # Iterate through each 2D sub-list in the 3x3x3 list\n",
    "    RectForceDistributions_ListofLists =  [[[[] for _ in range(n_bins)] for _ in range(n_bins)] for _ in range(n_bins)]\n",
    "    for i in range(len(rect_forceList)):\n",
    "        for j in range(len(rect_forceList[i])):\n",
    "            for k in range(len(rect_forceList[i][j])):\n",
    "                \n",
    "                if len(rect_forceList[i][j][k]) > 0:\n",
    "                # Calculate the average of the 1D sub-list\n",
    "                    avg = np.mean(rect_forceList[i][j][k])\n",
    "                    avg = np.round(avg, decimals=5)\n",
    "                # Replace the 1D sub-list with the average\n",
    "                    rect_force_avgs[i][j][k] = avg\n",
    "                    if len(rect_forceList[i][j][k]) > 4:\n",
    "                        force_skewness = skew(rect_forceList[i][j][k])\n",
    "                        #Leptokurtosis\n",
    "                        force_excess_kurtosis = kurtosis(rect_forceList[i][j][k], fisher=False)\n",
    "                    #Normal\n",
    "                        ks_test = stats.kstest(rect_forceList[i][j][k], 'norm', args=(np.mean(rect_forceList[i][j][k]), np.std(rect_forceList[i][j][k])))\n",
    "                        shapiro_test = stats.shapiro(rect_forceList[i][j][k])\n",
    "                        force_ks = ks_test.statistic\n",
    "                        force_shap = shapiro_test.statistic\n",
    "                        expon_stat, p_exp_ks = stats.kstest(rect_forceList[i][j][k], 'expon')\n",
    "                        lognormal_stat, p_lognormal_sw = stats.shapiro(np.log(rect_forceList[i][j][k]))\n",
    "                    else:\n",
    "                        force_skewness = np.nan\n",
    "                        force_excess_kurtosis = np.nan\n",
    "                        force_ks = np.nan\n",
    "                        force_shap = np.nan\n",
    "                        expon_stat = np.nan\n",
    "                        lognormal_stat = np.nan\n",
    "                    RectForceDistributions_ListofLists[i][j][k] = [avg, force_skewness, force_excess_kurtosis, force_ks, force_shap, expon_stat, lognormal_stat, len(rect_forceList[i][j][k])]\n",
    "          \n",
    "                else:\n",
    "                    rect_force_avgs[i][j][k] = 0\n",
    "                    force_skewness = np.nan\n",
    "                    force_excess_kurtosis = np.nan\n",
    "                    force_ks = np.nan\n",
    "                    force_shap = np.nan\n",
    "                    expon_stat = np.nan\n",
    "                    lognormal_stat = np.nan\n",
    "                    RectForceDistributions_ListofLists[i][j][k] = [0, force_skewness, force_excess_kurtosis, force_ks, force_shap, expon_stat, lognormal_stat, 0]\n",
    "\n",
    "    I_list = []\n",
    "    results_rectilinear = np.zeros((n_bins, n_bins, n_bins), dtype = int)\n",
    "    #make a results array that displays number in each bin\n",
    "    for j1 in range(0, n_bins):\n",
    "        for j2 in range(0, n_bins):\n",
    "            for j3 in range(0, n_bins):\n",
    "                comp = np.ones((Nxb, 3)) * np.array([j1, j2, j3])\n",
    "                match = np.all(comp == regFinder, axis=1)\n",
    "                Sums = np.sum(match)\n",
    "                results_rectilinear[j1, j2, j3] = Sums\n",
    "                if Sums > 0:\n",
    "                    I = np.where(match)[0]\n",
    "                    I_list.extend(I)\n",
    "    \n",
    "    I = np.array(I_list)\n",
    "    #print(results_rectilinear)\n",
    "\n",
    "    # flatten all layers of the data array\n",
    "    flattened_data = results_rectilinear.flatten()\n",
    "    #print(flattened_data)\n",
    "    \n",
    "    # generate colors based on the flattened data (using global normalization)\n",
    "    colors = generate_colors(flattened_data)\n",
    "    #print(colors)\n",
    "    \n",
    "    # reshape the colors array to match the shape of the data array\n",
    "    colors = np.array(colors).reshape((3, 3, 3, 4))\n",
    "    #print(colors)\n",
    "    \n",
    "    # plotting\n",
    "    fig3, axs = plt.subplots(1, 3, figsize=(6, 2))\n",
    "    \n",
    "    #for i in range(3):\n",
    "    #    axs[i].imshow(colors[i, :, :, :], aspect='auto')\n",
    "    #    axs[i].set_xticks([])\n",
    "    #    axs[i].set_yticks([])\n",
    "    #    axs[i].set_title(f'Layer {i}')\n",
    "    \n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "    \n",
    "    #Stats for the participant\n",
    "    total_samples = sum(points_in_pyramid40)\n",
    "    percentTime = [round(point_in_pyramid / total_samples * 100, 2) for point_in_pyramid in points_in_pyramid40]\n",
    "    #print(percentTime)\n",
    "    #total_mvts = sum(startpt_counts)\n",
    "    #percentStartMvt = [round(startpt_count / total_mvts * 100, 2) for startpt_count in startpt_counts]\n",
    "    \n",
    "    #Update the Main Hubs for stats\n",
    "    stats_icosahedron[subject] = percentTime\n",
    "\n",
    "    #stats_vel_icos[subject] = Vel_byzone\n",
    "    #stats_acc_icos[subject] = Accel_byzone\n",
    "\n",
    "    #stats_forceavg_icosahedron[subject] = forcedistributions_ListofLists\n",
    "    #stats_jointAngavg_icosahedron[subject] = JointAngle_listoflists\n",
    "    #stats_synergy_icosahedron[subject] = Synergy_listoflists\n",
    "    #stats_mvt_icosahedron[subject] = percentStartMvt\n",
    "\n",
    "    #Stats for rectilinear\n",
    "    total_samples_rectilinear = np.sum(results_rectilinear)\n",
    "    percentTime_rectilinear = [np.round(result / total_samples_rectilinear * 100, decimals=2) for result in results_rectilinear]\n",
    "    #print(percentTime_rectilinear)\n",
    "    #Update the Main Hubs for stats\n",
    "    percentTime_rectilinear = np.array(percentTime_rectilinear)\n",
    "    stats_rectilinear[subject] = percentTime_rectilinear.flatten()\n",
    "    #print('rectilinear stats')\n",
    "    #print(stats_rectilinear[subject])\n",
    "    #Force Rectilinear Stats\n",
    "    #flat_forcedistributions_list = [item for sublist1 in RectForceDistributions_ListofLists for sublist2 in sublist1 for item in sublist2]\n",
    "    #stats_forceavg_rectilinear[subject] = flat_forcedistributions_list\n",
    "\n",
    "    #summaryLists = [WristPositionhull.area, SynergyTotalSummary[0][0]]\n",
    "    #stats_summary[subject] = summaryLists\n",
    "    \n",
    "    return jointAngle_list, stats_summary, stats_icosahedron, stats_rectilinear, stats_vel_icos, stats_acc_icos, stats_forceavg_icosahedron, stats_forceavg_rectilinear, stats_jointAngavg_icosahedron, stats_synergy_icosahedron, stats_mvt_icosahedron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5406e62-ac2b-4f74-8681-9f22bf11dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Plot 3D figures\n",
    "def generate_circle_points(centroid, normal, radius=0.1, num_points=50):\n",
    "    # Create a vector perpendicular to the normal\n",
    "    if normal[0] == 0 and normal[1] == 0:\n",
    "        perp_vector = np.array([1, 0, 0])\n",
    "    else:\n",
    "        perp_vector = np.cross(normal, np.array([0, 0, 1]))\n",
    "    \n",
    "    # Normalize the perpendicular vector\n",
    "    perp_vector = perp_vector / np.linalg.norm(perp_vector)\n",
    "    \n",
    "    # Generate points on the circle in the plane perpendicular to the normal\n",
    "    circle_points = []\n",
    "    for theta in np.linspace(0, 2 * np.pi, num_points):\n",
    "        # Calculate position in 3D space\n",
    "        point = (\n",
    "            centroid +\n",
    "            radius * np.cos(theta) * perp_vector +\n",
    "            radius * np.sin(theta) * np.cross(normal, perp_vector)\n",
    "        )\n",
    "        circle_points.append(point)\n",
    "    return np.array(circle_points)\n",
    "    \n",
    "def generate_fixed_positions_on_face(vertices):\n",
    "    \"\"\"\n",
    "    Generates fixed positions for 19 participants on a triangular face:\n",
    "    - 3 participants on each median (3 medians = 9),\n",
    "    - 1 at the centroid,\n",
    "    - 3 additional participants in each of the 3 regions between the medians (9 total).\n",
    "    \"\"\"\n",
    "    # Calculate the centroid\n",
    "    centroid = np.mean(vertices, axis=0)\n",
    "\n",
    "    # Get the midpoints of each median\n",
    "    midpoints = []\n",
    "    for i in range(3):\n",
    "        start_vertex = vertices[i]\n",
    "        end_vertex = centroid  # The centroid is the end point of each median\n",
    "        midpoints.append(start_vertex + (end_vertex - start_vertex) * (1/4))  # 1/4 of the way to the centroid\n",
    "        midpoints.append(start_vertex + (end_vertex - start_vertex) * (2/4))  # 2/4 of the way to the centroid\n",
    "        midpoints.append(start_vertex + (end_vertex - start_vertex) * (3/4))  # 3/4 of the way to the centroid\n",
    "\n",
    "    # Combine the midpoints and centroid\n",
    "    positions = [centroid] + midpoints\n",
    "\n",
    "    # Now add 3 points in each region between the medians\n",
    "    # Get the start vertex and the centroid\n",
    "    restpoints= []\n",
    "    for i in range(3):\n",
    "        m1 = midpoints[3 * i]  # Midpoint at 1/2\n",
    "        m2 = midpoints[(3 * ((i + 1) % 3))]  # Midpoint at 1/2 of the next median\n",
    "        m3 = midpoints[3*i + 1]\n",
    "        m4 = midpoints[3 * ((i + 1) % 3) + 1]  # Midpoint at 3/4\n",
    "\n",
    "        # Add points in the regions between the median points\n",
    "        restpoints.append(m1 + (m2 - m1) * (1/3))  # 1/3 between m1 and m2\n",
    "        restpoints.append(m1 + (m2 - m1) * (2/3))  # 2/3 between m1 and m2\n",
    "        restpoints.append(m3 + (m4 - m3) * (1/2))  # Midpoint between m1 and m3\n",
    "\n",
    "    # Combine all positions\n",
    "    positions += restpoints\n",
    "\n",
    "    return np.array(positions)\n",
    "\n",
    "def generatePointer(vertices):\n",
    "    scale_factor = 0.1\n",
    "    #calculate the centroid\n",
    "    centroid = np.mean(vertices, axis=0)\n",
    "\n",
    "    trianglePointer = (vertices - vertices[0]) * scale_factor + vertices[0]\n",
    "\n",
    "    return np.array(trianglePointer)\n",
    "\n",
    "def plot3dIcosahedron(arr_main, title, colorbar_title, array_unique_pyramids, nt_ci_data, small, arr_comp=None):\n",
    "    # Icosahedron neurotypical average\n",
    "    colors = generate_colors(arr_main, arr_comp)\n",
    "    # convert colors to Plotly-compatible RGBA strings\n",
    "    rgba_colors = ['rgba({}, {}, {}, {})'.format(int(color[0]*255), int(color[1]*255), int(color[2]*255), color[3]) for color in colors]\n",
    "    # print the length of rgba_colors\n",
    "    print(\"Shape of rgba_colors:\", len(rgba_colors))\n",
    "    df_icosahedronSummary = pd.read_excel('/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/StatisticsCollection/ZoneDistribution_Icosahedron_r2.xlsx')\n",
    "    # Check the variability per Icosahedron zone of the neurotypicals\n",
    "    s_columns = [col for col in df_icosahedronSummary.columns if col.startswith('s')]\n",
    "    p_columns = [col for col in df_icosahedronSummary.columns if col.startswith('p')]\n",
    "\n",
    "    # load the OBJ file and parse its contents - PERSON FIGURINE\n",
    "    vertices = []\n",
    "    faces = []\n",
    "    with open('/Users/adithsrivatsa/Downloads/Man_Body_Valentino.obj', 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('v '):\n",
    "                # parse vertex coordinates (x, y, z)\n",
    "                vertex = list(map(float, line.strip().split()[1:]))\n",
    "                temp = vertex[0]\n",
    "                vertex[0] = (-1/300*0.65 * vertex[1]) + 0.15\n",
    "                vertex[1] = (1/660*0.65 * vertex[2]) - 1.35\n",
    "                vertex[2] = (-1/600*0.65 * temp) + 0.25\n",
    "                vertices.append(vertex)\n",
    "            elif line.startswith('f '):\n",
    "                # parse face indices (assuming triangular faces)\n",
    "                face_elements = line.strip().split()[1:]\n",
    "                face_indices = []\n",
    "                for element in face_elements:\n",
    "                    # parse the vertex index (ignore texture and normal indices)\n",
    "                    vertex_index = int(element.split('/')[0]) - 1\n",
    "                    face_indices.append(vertex_index)\n",
    "                faces.append(face_indices)\n",
    "\n",
    "    #make the centroid faces\n",
    "    # Calculate face centroids\n",
    "    face_centroids = []\n",
    "    for face in range(len(array_unique_pyramids)):\n",
    "        x_coords = array_unique_pyramids[face, 1:, 0]\n",
    "        y_coords = array_unique_pyramids[face, 1:, 1]\n",
    "        z_coords = array_unique_pyramids[face, 1:, 2]\n",
    "        centroid = (\n",
    "            np.mean(x_coords),\n",
    "            np.mean(y_coords),\n",
    "            np.mean(z_coords)\n",
    "        )\n",
    "        face_centroids.append(centroid)\n",
    "\n",
    "    #calculate the normals for the corresponding faces\n",
    "    face_normals = []\n",
    "    for face in range(len(array_unique_pyramids)):\n",
    "        # Get coordinates of three vertices of the face\n",
    "        v0 = array_unique_pyramids[face, 1]\n",
    "        v1 = array_unique_pyramids[face, 2]\n",
    "        v2 = array_unique_pyramids[face, 3]\n",
    "        # Calculate two edge vectors of the face\n",
    "        edge1 = v1 - v0\n",
    "        edge2 = v2 - v0\n",
    "        # Compute the cross product of the edge vectors to get the normal vector\n",
    "        normal = np.cross(edge1, edge2)\n",
    "        # Normalize the normal vector to get the unit direction vector\n",
    "        normal = normal / np.linalg.norm(normal)\n",
    "        # Append the normal vector to the list\n",
    "        face_normals.append(normal)\n",
    "\n",
    "    \n",
    "    #vertices and faces defined before 3D plots begin\n",
    "    # convert vertices and faces to numpy arrays\n",
    "    vertices = np.array(vertices)\n",
    "    faces = np.array(faces)\n",
    "    #define tick bounds\n",
    "    if arr_comp is None: \n",
    "        max_abs = max(abs(num) for num in arr_main)\n",
    "    else:\n",
    "        max_abs = max(max(abs(num) for num in arr_main), max(abs(num) for num in arr_comp))\n",
    "\n",
    "\n",
    "    ticklow = -math.ceil(max_abs)\n",
    "    tickmid = 0\n",
    "    tickhigh = math.ceil(max_abs)\n",
    "\n",
    "    diff_sample= arr_main - arr_main + 0.2 # make a test array of len(arr_main) but with the same value throughout\n",
    "    stroke_df = df_icosahedronSummary[p_columns]\n",
    "    if small == 1:\n",
    "        stroke_df = stroke_df.head(20)\n",
    "    else:\n",
    "        stroke_df = stroke_df.tail(20)\n",
    "    print(f'Stroke Data Shape {np.shape(stroke_df)}')\n",
    "    print(f'Stroke Data {stroke_df}')\n",
    "    \n",
    "    fig = go.Figure()\n",
    "        # Create the figurine dude\n",
    "    #fig.add_trace(go.Mesh3d(\n",
    "    #    x=vertices[:, 0],  # X coordinates of vertices\n",
    "    #    y=vertices[:, 1],  # Y coordinates of vertices\n",
    "    #    z=vertices[:, 2],  # Z coordinates of vertices\n",
    "    #    i=faces[:, 0],  # Indices of first vertex of each face\n",
    "    #    j=faces[:, 1],  # Indices of second vertex of each face\n",
    "    #    k=faces[:, 2],  # Indices of third vertex of each face\n",
    "    #    color='gray',  # Color of the figurine\n",
    "    #    opacity=1,\n",
    "    #    flatshading=True,\n",
    "    #))\n",
    "\n",
    "    #fig.add_trace(go.Scatter3d(\n",
    "    #    x=vertices[:, 0],  # X coordinates of vertices\n",
    "    #    y=vertices[:, 1],  # Y coordinates of vertices\n",
    "    #    z=vertices[:, 2],  # Z coordinates of vertices\n",
    "    #    mode='markers',\n",
    "    #    marker=dict(\n",
    "    #        size=4,\n",
    "    #        color='black',                # set color to an array/list of desired values\n",
    "    #        opacity=1\n",
    "    #    )\n",
    "    #))\n",
    "    \n",
    "    #officially add in the mesh for each face of the pyramid\n",
    "    num_subjects = 19  # Assuming 19 participants\n",
    "    for face in range(len(array_unique_pyramids)):\n",
    "        #print(f\"Face {face+1}\")\n",
    "        x_coords = array_unique_pyramids[face, 1:, 0] * 0.99\n",
    "        y_coords = array_unique_pyramids[face, 1:, 1] * 0.99\n",
    "        z_coords = array_unique_pyramids[face, 1:, 2] * 0.99\n",
    "        print(f' Face coordinates {face + 1}: {array_unique_pyramids[face]}')\n",
    "        i = [0, 1, 2]  # indices for vertices of the triangle\n",
    "        j = [1, 2, 0]\n",
    "        k = [2, 0, 1]\n",
    "        \n",
    "        vertices = array_unique_pyramids[face, 1:]\n",
    "         # Generate fixed positions on the face\n",
    "        fixed_positions = generate_fixed_positions_on_face(vertices)\n",
    "        zone_data = stroke_df.iloc[face]\n",
    "        #print(f'Zone Data: {zone_data}')\n",
    "        #add a black/gold triangle mesh 1/10 size of the face that points to the top triangle\n",
    "        trianglePointer = generatePointer(vertices)\n",
    "        #print(f'Face {face+1}: trianglePointer - {trianglePointer}')\n",
    "        fig.add_trace(go.Mesh3d(\n",
    "            x=trianglePointer[:, 0],\n",
    "            y=trianglePointer[:, 1],\n",
    "            z=trianglePointer[:, 2],\n",
    "            color='goldenrod',\n",
    "            opacity=1))\n",
    "        # Add a text label at a specific position\n",
    "        x_c, y_c, z_c = fixed_positions[0]\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=[x_c* 1.02],  # X coordinate of the text\n",
    "                y=[y_c * 1.02],  # Y coordinate of the text\n",
    "                z=[z_c * 1.02],  # Z coordinate of the text\n",
    "                text=face+1,  # The text value\n",
    "                mode='text',  # Display only text\n",
    "                textfont=dict(\n",
    "                    size=12,\n",
    "                    color='black'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "            \n",
    "        #print(f'Zone Data Size {np.shape(zone_data)}')\n",
    "        # For each subject, plot circles on the faces\n",
    "        for subject_idx, subject_value in enumerate(zone_data):\n",
    "        #indent this when u add the subject_idx\n",
    "            #subject_value = subject_values[face]  # Get the value for the current face - change to this when u have different values for each\n",
    "            # Generate circle points around the centroid\n",
    "            # Get the fixed position for this subject\n",
    "            if subject_idx < 19: # FIX THIS\n",
    "                fixed_position = fixed_positions[subject_idx]\n",
    "            x_c, y_c, z_c = fixed_position  # Get the centroid of the current face\n",
    "            normal = face_normals[face]  # Get the normal for the current face\n",
    "            #bring back the nt values to calculate radius and define the circle fill\n",
    "            ci_df = pd.DataFrame(nt_ci_data)\n",
    "            if small == 0:\n",
    "                ci_lower = (ci_df['CI Lower'][face+20] - 1e-6) * 100\n",
    "                #print(f'ci Lower: {ci_lower}')\n",
    "                ci_upper = (ci_df['CI Upper'][face+20] - 1e-6) * 100\n",
    "                #print(f'ci upper: {ci_upper}')\n",
    "                meanVal = (ci_df['Mean'][face+20]- 1e-6) * 100\n",
    "            else: \n",
    "                ci_lower = (ci_df['CI Lower'][face] - 1e-6) * 100\n",
    "                #print(f'ci Lower: {ci_lower}')\n",
    "                ci_upper = (ci_df['CI Upper'][face] - 1e-6) * 100\n",
    "                #print(f'ci upper: {ci_upper}')\n",
    "                meanVal = (ci_df['Mean'][face] - 1e-6) * 100\n",
    "            valueDiff = np.abs(subject_value - meanVal)\n",
    "            if small == 1:\n",
    "                radius = (0.002 + np.sqrt(valueDiff) * 0.02) / 2\n",
    "            else:\n",
    "                radius = 0.002 + np.sqrt(valueDiff) * 0.02\n",
    "            circle_points = generate_circle_points(np.array([x_c, y_c, z_c]), normal, radius=radius)\n",
    "        \n",
    "            # Separate circle points into x, y, z for plotting\n",
    "            x_circle = circle_points[:, 0]\n",
    "            y_circle = circle_points[:, 1]\n",
    "            z_circle = circle_points[:, 2]\n",
    "        \n",
    "\n",
    "            if subject_value > ci_upper:\n",
    "                #print('red')\n",
    "                fill_color = 'red'\n",
    "                fig.add_trace(go.Mesh3d(\n",
    "                    x=x_circle, y=y_circle, z=z_circle,\n",
    "                    color=fill_color,\n",
    "                    opacity=1,\n",
    "                    name=f'Filled red circle for subject {subject_idx + 1}',\n",
    "                    delaunayaxis='z' \n",
    "                ))\n",
    "                border_color = 'darkred'\n",
    "                fig.add_trace(go.Scatter3d(\n",
    "                    x=x_circle, y=y_circle, z=z_circle,\n",
    "                    mode='lines',\n",
    "                    line=dict(color=border_color, width=4),  # Adjust line width if needed\n",
    "                    name=f'Border for subject {subject_idx + 1}'\n",
    "                ))\n",
    "                #fig.add_trace(go.Scatter3d(\n",
    "                #    x=x_circle, y=y_circle, z=z_circle,\n",
    "                #    mode='lines',\n",
    "                #    line=dict(color='red', width=6),\n",
    "                #    name=f'Circle around centroid {face + 1}'\n",
    "                #))\n",
    "            elif subject_value < ci_lower:\n",
    "                #print('blue')\n",
    "                fill_color = 'blue'\n",
    "                fig.add_trace(go.Mesh3d(\n",
    "                    x=x_circle, y=y_circle, z=z_circle,\n",
    "                    color=fill_color,\n",
    "                    opacity=1,\n",
    "                    name=f'Filled blue circle for subject {subject_idx + 1}',\n",
    "                    delaunayaxis='z' \n",
    "                ))\n",
    "                border_color = 'darkblue'\n",
    "                fig.add_trace(go.Scatter3d(\n",
    "                    x=x_circle, y=y_circle, z=z_circle,\n",
    "                    mode='lines',\n",
    "                    line=dict(color=border_color, width=4),  # Adjust line width if needed\n",
    "                    name=f'Border for subject {subject_idx + 1}'\n",
    "                ))\n",
    "            else:\n",
    "            #Add the circle trace to the plot\n",
    "                #print('open')\n",
    "                fig.add_trace(go.Scatter3d(\n",
    "                    x=x_circle, y=y_circle, z=z_circle,\n",
    "                    mode='lines',\n",
    "                    line=dict(color='black', width=2),\n",
    "                    name=f'Circle for subject {subject_idx + 1}'\n",
    "                ))\n",
    "    \n",
    "        if arr_comp is None: \n",
    "              fig.add_trace(go.Mesh3d(\n",
    "                x=x_coords,\n",
    "                y=y_coords,\n",
    "                z=z_coords,\n",
    "                i=i,\n",
    "                j=j,\n",
    "                k=k,\n",
    "                intensity=[1, 1, 1],  # Set intensity to a single value\n",
    "                colorscale=[[0, 'white'], [1, 'white']],  # Make all faces white\n",
    "                opacity=1,\n",
    "                intensitymode='cell',\n",
    "                showscale=False  # Remove the colorbar\n",
    "            ))\n",
    "        else:\n",
    "           fig.add_trace(go.Mesh3d(\n",
    "                x=x_coords,\n",
    "                y=y_coords,\n",
    "                z=z_coords,\n",
    "                i=i,\n",
    "                j=j,\n",
    "                k=k,\n",
    "                intensity=[1, 1, 1],  # Set intensity to a single value\n",
    "                colorscale=[[0, 'white'], [1, 'white']],  # Make all faces white\n",
    "                opacity=1,\n",
    "                intensitymode='cell',\n",
    "                showscale=False  # Remove the colorbar\n",
    "            ))\n",
    "    \n",
    "        for edge in range(3):\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=[x_coords[edge], x_coords[(edge + 1) % 3]],\n",
    "                y=[y_coords[edge], y_coords[(edge + 1) % 3]],\n",
    "                z=[z_coords[edge], z_coords[(edge + 1) % 3]],\n",
    "                mode='lines',\n",
    "                line=dict(color='black', width=2)\n",
    "            ))\n",
    "\n",
    "        # Update layout total\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        scene=dict(\n",
    "            aspectmode='data',\n",
    "            xaxis=dict(title='X Axis'),\n",
    "            yaxis=dict(title='Y Axis'),\n",
    "            zaxis=dict(title='Z Axis')\n",
    "        ),\n",
    "        width=800,\n",
    "        height=800,\n",
    "        showlegend=False,\n",
    "        margin=dict(l=50, r=50, b=50, t=50),\n",
    "    )\n",
    "\n",
    "        \n",
    "    #clear out the background color\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(visible=False),\n",
    "        yaxis=dict(visible=False),\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "\n",
    "def generate_circle_positions(x_rect, y_rect, z_rect, z_offset=-0.01):\n",
    "    # Calculate the bounds of the square\n",
    "    x_min, x_max = min(x_rect), max(x_rect)\n",
    "    y_min, y_max = min(y_rect), max(y_rect)\n",
    "    z_fixed = np.mean(z_rect) + z_offset  # Slightly in front of the plane\n",
    "\n",
    "    # Define a 4x5 grid (20 positions, use only 19)\n",
    "    x_grid = np.linspace(x_min+0.05, x_max-0.05, 5)\n",
    "    y_grid = np.linspace(y_min+0.05, y_max-0.05, 4)\n",
    "    x_positions, y_positions = np.meshgrid(x_grid, y_grid)\n",
    "    \n",
    "    # Flatten the grid and select the first 19 positions\n",
    "    x_flat = x_positions.flatten()[:19]\n",
    "    y_flat = y_positions.flatten()[:19]\n",
    "    z_flat = [z_fixed] * 19  # Same z-offset for all circles\n",
    "\n",
    "    # Combine into a list of tuples\n",
    "    positions = list(zip(x_flat, y_flat, z_flat))\n",
    "    #print(f'circle positions: {positions}')\n",
    "    return positions\n",
    "\n",
    "def plot3dRectilinear(stroke_diff_df, Rect_nt_ci_data, title, arr_comp=None):\n",
    "\n",
    "    # load the OBJ file and parse its contents - PERSON FIGURINE\n",
    "    vertices = []\n",
    "    faces = []\n",
    "    with open('/Users/adithsrivatsa/Downloads/Man_Body_Valentino.obj', 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('v '):\n",
    "                # parse vertex coordinates (x, y, z)\n",
    "                vertex = list(map(float, line.strip().split()[1:]))\n",
    "                temp = vertex[0]\n",
    "                vertex[0] = (-1/300*0.65 * vertex[1]) + 0.15\n",
    "                vertex[1] = (1/660*0.65 * vertex[2]) - 1.35\n",
    "                vertex[2] = (-1/600*0.65 * temp) + 0.25\n",
    "                vertices.append(vertex)\n",
    "            elif line.startswith('f '):\n",
    "                # parse face indices (assuming triangular faces)\n",
    "                face_elements = line.strip().split()[1:]\n",
    "                face_indices = []\n",
    "                for element in face_elements:\n",
    "                    # parse the vertex index (ignore texture and normal indices)\n",
    "                    vertex_index = int(element.split('/')[0]) - 1\n",
    "                    face_indices.append(vertex_index)\n",
    "                faces.append(face_indices)\n",
    "    vertices = np.array(vertices)\n",
    "    faces = np.array(faces)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    # Define the coordinates for each bin\n",
    "    #test s08 and get max bin_limits\n",
    "    #print(\"Shape of bin_limits\", np.shape(bin_limits))\n",
    "    count = 0\n",
    "    for zi in range(2, -1, -1):\n",
    "        for yi in range(2, -1, -1):\n",
    "            for xi in range(2, -1, -1):\n",
    "                # find the vertices for each rectangle\n",
    "                x_rect = []\n",
    "                y_rect = []\n",
    "                z_rect = []\n",
    "                i_rect = []\n",
    "                j_rect = []\n",
    "                k_rect = []\n",
    "                \n",
    "                x_rect.extend([bin_limits[xi, 0], bin_limits[xi + 1, 0], bin_limits[xi + 1, 0], bin_limits[xi, 0]])\n",
    "                y_rect.extend([bin_limits[yi, 1], bin_limits[yi, 1], bin_limits[yi + 1, 1], bin_limits[yi + 1, 1]])\n",
    "                z_rect.extend([bin_limits[zi, 2], bin_limits[zi, 2], bin_limits[zi, 2], bin_limits[zi, 2]])\n",
    "    \n",
    "                #plotly works with triangular faces so find these\n",
    "                vertex_counter = 0\n",
    "                i_rect.extend([vertex_counter, vertex_counter, vertex_counter + 1])\n",
    "                j_rect.extend([vertex_counter + 1, vertex_counter + 2, vertex_counter + 2])\n",
    "                k_rect.extend([vertex_counter + 2, vertex_counter + 3, vertex_counter + 3])\n",
    "\n",
    "\n",
    "                #Plot the mesh in place?\n",
    "                fig.add_trace(go.Mesh3d(\n",
    "                    x=x_rect,\n",
    "                    y=y_rect,\n",
    "                    z=z_rect,\n",
    "                    i=i_rect,\n",
    "                    j=j_rect,\n",
    "                    k=k_rect,\n",
    "                    intensity=[1, 5, 10],\n",
    "                    colorscale=[[0, 'white'], [1, 'white']],\n",
    "                    intensitymode ='cell',\n",
    "                ))\n",
    "\n",
    "                #plot circles for each person\n",
    "                circle_positions = generate_circle_positions(x_rect, y_rect, z_rect)\n",
    "                for col in range(stroke_diff_df.shape[1]):\n",
    "                    position = circle_positions[col]\n",
    "                    x_c, y_c, z_c = position\n",
    "                    #radius = stroke_diff_df.iloc[2, col] #same radius for everything for now\n",
    "                    curr_val = stroke_diff_df.iloc[count, col]\n",
    "                    radius = 0.002 + np.sqrt(np.abs(curr_val * 100)) * 0.01\n",
    "                    theta = np.linspace(0, 2 * np.pi, 100)\n",
    "                    x_circle = x_c + radius * np.cos(theta)\n",
    "                    y_circle = y_c + radius * np.sin(theta)\n",
    "                    z_circle = [z_c] * len(theta)\n",
    "\n",
    "                    ci_upper = Rect_nt_ci_data[count]['CI Upper'] - 1e-6 - Rect_nt_ci_data[count]['Mean']\n",
    "                    ci_lower = Rect_nt_ci_data[count]['CI Lower'] - 1e-6 - Rect_nt_ci_data[count]['Mean']\n",
    "                    #print(f'{count} zone: ci upper - {ci_upper}, ci lower - {ci_lower}')\n",
    "\n",
    "                    if curr_val > ci_upper:\n",
    "                        #print('red')\n",
    "                        fill_color = 'red'\n",
    "                        fig.add_trace(go.Mesh3d(\n",
    "                            x=x_circle, y=y_circle, z=z_circle,\n",
    "                            color=fill_color,\n",
    "                            opacity=1,\n",
    "                        ))\n",
    "                        border_color = 'darkred'\n",
    "                        fig.add_trace(go.Scatter3d(\n",
    "                            x=x_circle, y=y_circle, z=z_circle,\n",
    "                            mode='lines',\n",
    "                            line=dict(color=border_color, width=2),  # Adjust line width if needed\n",
    "                        ))\n",
    "                        #fig.add_trace(go.Scatter3d(\n",
    "                        #    x=x_circle, y=y_circle, z=z_circle,\n",
    "                        #    mode='lines',\n",
    "                        #    line=dict(color='red', width=6),\n",
    "                        #    name=f'Circle around centroid {face + 1}'\n",
    "                        #))\n",
    "                    elif curr_val < ci_lower:\n",
    "                        #print('blue')\n",
    "                        fill_color = 'blue'\n",
    "                        fig.add_trace(go.Mesh3d(\n",
    "                            x=x_circle, y=y_circle, z=z_circle,\n",
    "                            color=fill_color,\n",
    "                            opacity=1,\n",
    "                        ))\n",
    "                        border_color = 'darkblue'\n",
    "                        fig.add_trace(go.Scatter3d(\n",
    "                            x=x_circle, y=y_circle, z=z_circle,\n",
    "                            mode='lines',\n",
    "                            line=dict(color=border_color, width=2),  # Adjust line width if needed\n",
    "                        ))\n",
    "                    else:\n",
    "                        #print('open')\n",
    "                        fig.add_trace(go.Scatter3d(\n",
    "                            x=x_circle, y=y_circle, z=z_circle,\n",
    "                            mode='lines',\n",
    "                            line=dict(color='black', width=2),\n",
    "                        ))\n",
    "    \n",
    "                edges = []\n",
    "                for i, j, k in zip(i_rect, j_rect, k_rect):\n",
    "                    #edges.append((x_rect[i], y_rect[i], z_rect[i]))\n",
    "                    edges.append((x_rect[j], y_rect[j], z_rect[j]))\n",
    "                    #edges.append((x_rect[j], y_rect[j], z_rect[j]))\n",
    "                    edges.append((x_rect[k], y_rect[k], z_rect[k]))\n",
    "                    edges.append((x_rect[k], y_rect[k], z_rect[k]))\n",
    "                    #edges.append((x_rect[i], y_rect[i], z_rect[i]))\n",
    "                \n",
    "                # Plot edges\n",
    "                fig.add_trace(go.Scatter3d(\n",
    "                    x=[edge[0] for edge in edges],\n",
    "                    y=[edge[1] for edge in edges],\n",
    "                    z=[edge[2] for edge in edges],\n",
    "                    mode='lines',\n",
    "                    line=dict(color='black', width=2),\n",
    "                ))\n",
    "                count +=1\n",
    "                #print(count)\n",
    "    \n",
    "    \n",
    "    #Define figurine in this plot\n",
    "    # Create a Mesh3d trace using the parsed data\n",
    "    #fig.add_trace(go.Mesh3d(\n",
    "    #    x=vertices[:, 0],  # X coordinates of vertices\n",
    "    #    y=vertices[:, 1],  # Y coordinates of vertices\n",
    "    #    z=vertices[:, 2],  # Z coordinates of vertices\n",
    "    #    i=faces[:, 0],  # Indices of first vertex of each face\n",
    "    #    j=faces[:, 1],  # Indices of second vertex of each face\n",
    "    #    k=faces[:, 2],  # Indices of third vertex of each face\n",
    "    #    color='grey',  # Color of the figurine\n",
    "    #    opacity=1,\n",
    "    #    flatshading=True,\n",
    "    #))\n",
    "    \n",
    "    # Hide axes\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        scene=dict(\n",
    "            aspectmode='data',\n",
    "            xaxis=dict(title='X Axis'),\n",
    "            yaxis=dict(title='Y Axis'),\n",
    "            zaxis=dict(title='Z Axis')\n",
    "        ),\n",
    "        width=800,\n",
    "        height=800,\n",
    "        showlegend=False,\n",
    "        margin=dict(l=50, r=50, b=50, t=50),\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        paper_bgcolor='white',  # Background of the figure area\n",
    "        scene=dict(\n",
    "            xaxis=dict(showgrid=False, showbackground=True, backgroundcolor='white'),\n",
    "            yaxis=dict(showgrid=False, showbackground=True, backgroundcolor='white'),\n",
    "            zaxis=dict(showgrid=False, showbackground=True, backgroundcolor='white'),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "def plot3dDust(df, title, right):\n",
    "    # Icosahedron neurotypical average\n",
    "    if right == 1:\n",
    "        shoulder_cols = ['ShoulderRight_X', 'ShoulderRight_Y', 'ShoulderRight_Z']\n",
    "        wrist_cols = ['WristRight_X', 'WristRight_Y', 'WristRight_Z']\n",
    "    else:\n",
    "        shoulder_cols = ['ShoulderLeft_X', 'ShoulderLeft_Y', 'ShoulderLeft_Z']\n",
    "        wrist_cols = ['WristLeft_X', 'WristLeft_Y', 'WristLeft_Z']\n",
    "    \n",
    "    \n",
    "    center = df[shoulder_cols].loc[:100, :].mean()\n",
    "    center.astype(np.int64)\n",
    "    df = df.drop(df.index[-1])\n",
    "    if right == 1:\n",
    "        df['Wrist_X'] = df['WristRight_X'] - center['ShoulderRight_X']\n",
    "        df['Wrist_Y'] = df['WristRight_Y'] - center['ShoulderRight_Y']\n",
    "        df['Wrist_Z'] = df['WristRight_Z'] - center['ShoulderRight_Z']\n",
    "        df['Hip_X'] = df['HipRight_X'] - center['ShoulderRight_X']\n",
    "        df['Hip_Y'] = df['HipRight_Y'] - center['ShoulderRight_Y']\n",
    "        df['Hip_Z'] = df['HipRight_Z'] - center['ShoulderRight_Z']\n",
    "        df['Elbow_X'] = df['ElbowRight_X'] - center['ShoulderRight_X']\n",
    "        df['Elbow_Y'] = df['ElbowRight_Y'] - center['ShoulderRight_Y']\n",
    "        df['Elbow_Z'] = df['ElbowRight_Z'] - center['ShoulderRight_Z']\n",
    "        df['Hand_X'] = df['HandRight_X'] - center['ShoulderRight_X']\n",
    "        df['Hand_Y'] = df['HandRight_Y'] - center['ShoulderRight_Y']\n",
    "        df['Hand_Z'] = df['HandRight_Z'] - center['ShoulderRight_Z']\n",
    "        df['Shoulder_X'] = df['ShoulderRight_X'] - center['ShoulderRight_X']\n",
    "        df['Shoulder_Y'] = df['ShoulderRight_Y'] - center['ShoulderRight_Y']\n",
    "        df['Shoulder_Z'] = df['ShoulderRight_Z'] - center['ShoulderRight_Z']\n",
    "        df['Thumb_X'] = df['ThumbRight_X'] - center['ShoulderRight_X']\n",
    "        df['Thumb_Y'] = df['ThumbRight_Y'] - center['ShoulderRight_Y']\n",
    "        df['Thumb_Z'] = df['ThumbRight_Z'] - center['ShoulderRight_Z']\n",
    "        center['ShoulderRight_X'] -= center['ShoulderRight_X']\n",
    "        center['ShoulderRight_Y'] -= center['ShoulderRight_Y']\n",
    "        center['ShoulderRight_Z'] -= center['ShoulderRight_Z']\n",
    "    else:\n",
    "        df['Wrist_X'] = -(df['WristLeft_X'] - center['ShoulderLeft_X'])\n",
    "        df['Wrist_Y'] = df['WristLeft_Y'] - center['ShoulderLeft_Y']\n",
    "        df['Wrist_Z'] = df['WristLeft_Z'] - center['ShoulderLeft_Z']\n",
    "        df['Hip_X'] = -(df['HipLeft_X'] - center['ShoulderLeft_X'])\n",
    "        df['Hip_Y'] = df['HipLeft_Y'] - center['ShoulderLeft_Y']\n",
    "        df['Hip_Z'] = df['HipLeft_Z'] - center['ShoulderLeft_Z']\n",
    "        df['Elbow_X'] = -(df['ElbowLeft_X'] - center['ShoulderLeft_X'])\n",
    "        df['Elbow_Y'] = df['ElbowLeft_Y'] - center['ShoulderLeft_Y']\n",
    "        df['Elbow_Z'] = df['ElbowLeft_Z'] - center['ShoulderLeft_Z']\n",
    "        df['Hand_X'] = -(df['HandLeft_X'] - center['ShoulderLeft_X'])\n",
    "        df['Hand_Y'] = df['HandLeft_Y'] - center['ShoulderLeft_Y']\n",
    "        df['Hand_Z'] = df['HandLeft_Z'] - center['ShoulderLeft_Z']\n",
    "        df['Shoulder_X'] = -(df['ShoulderLeft_X'] - center['ShoulderLeft_X'])\n",
    "        df['Shoulder_Y'] = df['ShoulderLeft_Y'] - center['ShoulderLeft_Y']\n",
    "        df['Shoulder_Z'] = df['ShoulderLeft_Z'] - center['ShoulderLeft_Z']\n",
    "        df['Thumb_X'] = -(df['ThumbLeft_X'] - center['ShoulderLeft_X'])\n",
    "        df['Thumb_Y'] = df['ThumbLeft_Y'] - center['ShoulderLeft_Y']\n",
    "        df['Thumb_Z'] = df['ThumbLeft_Z'] - center['ShoulderLeft_Z']\n",
    "        center['ShoulderLeft_X'] -= center['ShoulderLeft_X']\n",
    "        center['ShoulderLeft_Y'] -= center['ShoulderLeft_Y']\n",
    "        center['ShoulderLeft_Z'] -= center['ShoulderLeft_Z']\n",
    "        #call filter95 function to cut >95% percentile distances from shoulder\n",
    "\n",
    "    fs = 30\n",
    "    trim_for_abstract = fs * 120 #trim the first 2 minutes of the data\n",
    "    df = df.loc[:trim_for_abstract, :]\n",
    "    \n",
    "    print(f'Filter95 Check {df.shape}')\n",
    "    df_filtered = filterPositionData(df, center, right, subject)\n",
    "    print('filter iqr+lp+smoothened shape')\n",
    "    print(df_filtered.shape)\n",
    "    \n",
    "    # load the OBJ file and parse its contents - PERSON FIGURINE\n",
    "    vertices = []\n",
    "    faces = []\n",
    "    with open('/Users/adithsrivatsa/Downloads/Man_Body_Valentino.obj', 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('v '):\n",
    "                # parse vertex coordinates (x, y, z)\n",
    "                vertex = list(map(float, line.strip().split()[1:]))\n",
    "                temp = vertex[0]\n",
    "                vertex[0] = (-1/600 * vertex[1]) + 0.1\n",
    "                vertex[1] = (1/880 * vertex[2]) - 1.8\n",
    "                vertex[2] = (-1/800 * temp) + 0.25\n",
    "                vertices.append(vertex)\n",
    "            elif line.startswith('f '):\n",
    "                # parse face indices (assuming triangular faces)\n",
    "                face_elements = line.strip().split()[1:]\n",
    "                face_indices = []\n",
    "                for element in face_elements:\n",
    "                    # parse the vertex index (ignore texture and normal indices)\n",
    "                    vertex_index = int(element.split('/')[0]) - 1\n",
    "                    face_indices.append(vertex_index)\n",
    "                faces.append(face_indices)\n",
    "        \n",
    "    #vertices and faces defined before 3D plots begin\n",
    "    # convert vertices and faces to numpy arrays\n",
    "    vertices = np.array(vertices)\n",
    "    faces = np.array(faces)\n",
    "    fig = go.Figure()\n",
    "    fig = px.scatter_3d(df_filtered, x=\"Wrist_X\", y=\"Wrist_Y\", z=\"Wrist_Z\")\n",
    "    fig.update_traces(marker = dict(size = 2))\n",
    "\n",
    "    # Create the figurine dude\n",
    "    fig.add_trace(go.Mesh3d(\n",
    "        x=vertices[:, 0],  # X coordinates of vertices\n",
    "        y=vertices[:, 1],  # Y coordinates of vertices\n",
    "        z=vertices[:, 2],  # Z coordinates of vertices\n",
    "        i=faces[:, 0],  # Indices of first vertex of each face\n",
    "        j=faces[:, 1],  # Indices of second vertex of each face\n",
    "        k=faces[:, 2],  # Indices of third vertex of each face\n",
    "        color='lightblue',  # Color of the figurine\n",
    "        opacity=1,\n",
    "        flatshading=True,\n",
    "    ))\n",
    "\n",
    "        # Update layout total\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        scene=dict(\n",
    "            aspectmode='data',\n",
    "            xaxis=dict(title='X Axis'),\n",
    "            yaxis=dict(title='Y Axis'),\n",
    "            zaxis=dict(title='Z Axis')\n",
    "        ),\n",
    "        width=1000,\n",
    "        height=1000,\n",
    "        showlegend=False,\n",
    "        margin=dict(l=50, r=50, b=50, t=50),\n",
    "    )\n",
    "        \n",
    "    #clear out the background color\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(visible=False),\n",
    "        yaxis=dict(visible=False),\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "    # Show the figure\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf1999-b68b-4cc9-b581-9474ffcdc057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Overall looping through each subject data\n",
    "\n",
    "directory = '/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/'\n",
    "#initialize data zones for icos\n",
    "stats_icosahedron = pd.DataFrame(index=range(1, 41))\n",
    "stats_forceavg_icosahedron = pd.DataFrame(index=range(1, 41))\n",
    "stats_jointAngavg_icosahedron = pd.DataFrame(index=range(1, 41))\n",
    "stats_synergy_icosahedron = pd.DataFrame(index=range(1, 41))\n",
    "stats_vel_icos = pd.DataFrame(index=range(1, 41))\n",
    "stats_acc_icos = pd.DataFrame(index=range(1, 41))\n",
    "stats_mvt_icosahedron = pd.DataFrame(index=range(1,41))\n",
    "stats_summary = pd.DataFrame(index=range(1,3))\n",
    "zone_data = ['Zone ' + str(i) for i in range(1, 41)]\n",
    "stats_icosahedron['Zones'] = zone_data\n",
    "stats_vel_icos['Zones'] = zone_data\n",
    "stats_acc_icos['Zones'] = zone_data\n",
    "stats_forceavg_icosahedron['Zones'] = zone_data\n",
    "stats_jointAngavg_icosahedron['Zones'] = zone_data\n",
    "stats_synergy_icosahedron['Zones'] = zone_data\n",
    "stats_mvt_icosahedron['Zones'] = zone_data\n",
    "#THe fields for summary - Convhull, synergy correlations (not zone-based)\n",
    "parameter_names = ['Convhull', 'Synergy']\n",
    "stats_summary['Parameters'] = parameter_names\n",
    "#initialize data zones for rect\n",
    "stats_rectilinear = pd.DataFrame(index=range(1, 28))\n",
    "stats_forceavg_rectilinear = pd.DataFrame(index=range(1, 28))\n",
    "zone_data = ['Zone ' + str(i) for i in range(1, 28)]\n",
    "stats_rectilinear['Zones'] = zone_data\n",
    "stats_forceavg_rectilinear['Zones'] = zone_data\n",
    "\n",
    "cumData = [[] for _ in range(3)]\n",
    "rightDomList = ['s04', 's06', 's08', 's10', 's11', 's12', 's14', 'p01', 'p03', 'p10', 'p12', 'p13', 'p17', 'p33', 'p37']\n",
    "right = 1\n",
    "jointAngle_list = []\n",
    "\n",
    "#parse through the directory, go through each csv file\n",
    "for filename in sorted(os.listdir(directory)):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    if os.path.isfile(filepath) and not fnmatch.fnmatch(filename, '.DS_Store'):\n",
    "        ind = filename.find('_')\n",
    "        subject = filename[:ind]\n",
    "        #Check if right or left to be analyzed\n",
    "        #print(filename)\n",
    "        print(subject)\n",
    "        if subject in rightDomList:\n",
    "            right = 1\n",
    "        else:\n",
    "            right = 0\n",
    "        print(right)\n",
    "        #print(filepath)\n",
    "        df = pd.read_csv(filepath)\n",
    "        #Call the big Function to assess percent Time spent in each zone\n",
    "        shape_modeling(df, right, subject, jointAngle_list, stats_summary, stats_icosahedron, stats_rectilinear, stats_vel_icos, stats_acc_icos, stats_forceavg_icosahedron, stats_forceavg_rectilinear, stats_jointAngavg_icosahedron, stats_synergy_icosahedron, stats_mvt_icosahedron, cumData)\n",
    "\n",
    "#define file names and path\n",
    "directoryStats = '/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/StatisticsCollection/'\n",
    "Stats_icos_filename = 'ZoneDistribution_Icosahedron_r2.xlsx'\n",
    "Stats_rect_filename = 'ZoneDistribution_Rectilinear.xlsx'\n",
    "fullStorage_icos_path = os.path.join(directoryStats, Stats_icos_filename)\n",
    "fullStorage_rect_path = os.path.join(directoryStats, Stats_rect_filename)\n",
    "\n",
    "#for vel and accel\n",
    "stats_vel_icos_filename ='ZoneVelocity_Icosahedron.xlsx'\n",
    "stats_accel_icos_filename = 'ZoneAcceleration_Icosahedron.xlsx'\n",
    "fullStorage_vel_path = os.path.join(directoryStats, stats_vel_icos_filename)\n",
    "fullStorage_accel_path = os.path.join(directoryStats, stats_accel_icos_filename)\n",
    "\n",
    "#for forces\n",
    "Stats_forces_icos_filename = 'ZoneForces_Icosahedron.xlsx'\n",
    "Stats_forces_rect_filename = 'ZoneForces_Rectilinear.xlsx'\n",
    "fullStorageForces_icos_path = os.path.join(directoryStats, Stats_forces_icos_filename)\n",
    "fullStorageForces_rect_path = os.path.join(directoryStats, Stats_forces_rect_filename)\n",
    "\n",
    "#for jointAngles\n",
    "Stats_jointAngles_icos_filename = 'ZoneJointAngles_Icosahedron.xlsx'\n",
    "fullStorageJA_icos_path = os.path.join(directoryStats, Stats_jointAngles_icos_filename)\n",
    "Stats_synergy_icos_filename = 'ZoneSynergy_Icosahedron.xlsx'\n",
    "fullStorageSynergy_icos_path = os.path.join(directoryStats, Stats_synergy_icos_filename)\n",
    "\n",
    "#for movement\n",
    "Stats_movement_icos_filename = 'ZoneMovement_Icosahedron.xlsx'\n",
    "fullStorageMVT_icos_path = os.path.join(directoryStats, Stats_movement_icos_filename)\n",
    "\n",
    "#for summer\n",
    "stats_summary_filename = 'ParameterSummarybySubject.xlsx'\n",
    "fullsummaryStorage_path = os.path.join(directoryStats, stats_summary_filename)\n",
    "\n",
    "# write the stats_df to an Excel file\n",
    "stats_icosahedron.to_excel(fullStorage_icos_path, engine='openpyxl', index=False)\n",
    "stats_rectilinear.to_excel(fullStorage_rect_path, engine='openpyxl', index=False)\n",
    "stats_forceavg_icosahedron.to_excel(fullStorageForces_icos_path, engine='openpyxl', index=False)\n",
    "stats_forceavg_rectilinear.to_excel(fullStorageForces_rect_path, engine='openpyxl', index=False)\n",
    "stats_jointAngavg_icosahedron.to_excel(fullStorageJA_icos_path, engine='openpyxl', index=False)\n",
    "stats_synergy_icosahedron.to_excel(fullStorageSynergy_icos_path, engine='openpyxl', index=False)\n",
    "stats_vel_icos.to_excel(fullStorage_vel_path, engine='openpyxl', index=False)\n",
    "stats_acc_icos.to_excel(fullStorage_accel_path, engine='openpyxl', index=False)\n",
    "stats_mvt_icosahedron.to_excel(fullStorageMVT_icos_path, engine='openpyxl', index=False)\n",
    "stats_summary.to_excel(fullsummaryStorage_path, engine='openpyxl', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f3c4a4-2fb8-4c91-a1d4-81ce845233aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Analyze Wrist Position Data\n",
    "\n",
    "#ICOSAHEDRON % TIME Wrist Position - Linear Regression\n",
    "df_icosahedronSummary = pd.read_excel('/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/StatisticsCollection/ZoneDistribution_Icosahedron_r2.xlsx')\n",
    "df_rectilinearSummary = pd.read_excel('/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/StatisticsCollection/ZoneDistribution_Rectilinear.xlsx')\n",
    "clinical_df = pd.read_csv('/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/ClinicalFiles/phase1_clinicalscores.csv')\n",
    "clinical_aratBreakdown = pd.read_csv('/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/ClinicalFiles/ExoNETPhase1-AllDataNoPHI_DATA_LABELS_2024-07-22_1711.csv')\n",
    "directory = '/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/'\n",
    "#parse through the directory, go through each csv file\n",
    "fig100 = go.Figure()\n",
    "figarat = go.Figure()\n",
    "figGross = go.Figure()\n",
    "figGrip = go.Figure()\n",
    "figGraPinch = go.Figure()\n",
    "figSynergy = go.Figure()\n",
    "figOther = go.Figure()\n",
    "color_count = 0\n",
    "ttest_results_per_zone = []\n",
    "for zone in range(40):\n",
    "    percent_time = []\n",
    "    arat_scores = []\n",
    "    fmue_scores = []\n",
    "    arat_Gross = []\n",
    "    arat_Grip = []\n",
    "    arat_GraPinch = []\n",
    "    fmue_synergy = []\n",
    "    zone_time_ss = []\n",
    "    zone_time_nt = []\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath) and not fnmatch.fnmatch(filename, '.DS_Store'):\n",
    "            ind = filename.find('_')\n",
    "            subject = filename[:ind]\n",
    "            if subject[0] == 'p':\n",
    "                fmue_curr = clinical_df[(clinical_df['subject'].str.lower() == subject) & (clinical_df['session'].str.lower() == 'baseline')]['fmue']\n",
    "                arat_curr = clinical_df[(clinical_df['subject'].str.lower() == subject) & (clinical_df['session'].str.lower() == 'baseline')]['arat']\n",
    "                ARATbreakdown_curr = clinical_aratBreakdown[(clinical_aratBreakdown['Record ID'].str.lower() == subject) & (clinical_aratBreakdown['Event Name'].str.lower() == 'baseline evals')]\n",
    "                Synergylist_backup = clinical_aratBreakdown[(clinical_aratBreakdown['Record ID'].str.lower() == subject) & (clinical_aratBreakdown['Event Name'].str.lower() == 'screening')]\n",
    "                Gross_curr = int(ARATbreakdown_curr['Gross Movement Total Score'])\n",
    "                Grip_curr = int(ARATbreakdown_curr['Grip Subtest Total Score'])\n",
    "                GraPinch_curr = [int(ARATbreakdown_curr['Grasp Subtest Total Score']), int(ARATbreakdown_curr['Pinch Subtest Total Score'])]\n",
    "                GraPinch_curr = np.sum(GraPinch_curr)\n",
    "                fmue_curr = int(fmue_curr)\n",
    "                arat_curr = int(arat_curr)\n",
    "                if ARATbreakdown_curr['Biceps- Flexor'].isna().any():\n",
    "                    synergy_list = [int(Synergylist_backup['Biceps- Flexor']), int(Synergylist_backup['Triceps - Extensor']), int(Synergylist_backup['Elevation']), int(Synergylist_backup['Retraction']), int(Synergylist_backup['Abduction']), int(Synergylist_backup['External Rotation']), int(Synergylist_backup['Elbow Flexion']), int(Synergylist_backup['Supination']), int(Synergylist_backup['Abduction']), int(Synergylist_backup['Adduction/Internal Rotation']), int(Synergylist_backup['Elbow Extension']), int(Synergylist_backup['Pronation']), int(Synergylist_backup['Hand to Lumbar Spine']), int(Synergylist_backup['Shoulder flexion to 90 degrees with elbow at 0 degrees and forearm in neutral']), int(Synergylist_backup['Pronation/Supination with elbow at 90 degrees']), int(Synergylist_backup['Abduction to 90 degrees']), int(Synergylist_backup['Shoulder flexion 90 to 180 degrees with elbow at 0 degrees and forearm in neutral']), int(Synergylist_backup['Pronation/Supination with elbow at 0 degrees and shoulder flexed 30 to 90 degrees']), int(Synergylist_backup['Test deep tendon relfexes of the biceps OR long finger flexors, then triceps'])]\n",
    "                else:\n",
    "                    synergy_list = [int(ARATbreakdown_curr['Biceps- Flexor']), int(ARATbreakdown_curr['Triceps - Extensor']), int(ARATbreakdown_curr['Elevation']), int(ARATbreakdown_curr['Retraction']), int(ARATbreakdown_curr['Abduction']), int(ARATbreakdown_curr['External Rotation']), int(ARATbreakdown_curr['Elbow Flexion']), int(ARATbreakdown_curr['Supination']), int(ARATbreakdown_curr['Abduction']), int(ARATbreakdown_curr['Adduction/Internal Rotation']), int(ARATbreakdown_curr['Elbow Extension']), int(ARATbreakdown_curr['Pronation']), int(ARATbreakdown_curr['Hand to Lumbar Spine']), int(ARATbreakdown_curr['Shoulder flexion to 90 degrees with elbow at 0 degrees and forearm in neutral']), int(ARATbreakdown_curr['Pronation/Supination with elbow at 90 degrees']), int(ARATbreakdown_curr['Abduction to 90 degrees']), int(ARATbreakdown_curr['Shoulder flexion 90 to 180 degrees with elbow at 0 degrees and forearm in neutral']), int(ARATbreakdown_curr['Pronation/Supination with elbow at 0 degrees and shoulder flexed 30 to 90 degrees']), int(ARATbreakdown_curr['Test deep tendon relfexes of the biceps OR long finger flexors, then triceps'])]\n",
    "                synergy_curr = np.sum(synergy_list)\n",
    "                zone_time_ss.append(df_icosahedronSummary[subject][zone])\n",
    "            else:\n",
    "                fmue_curr = 66\n",
    "                arat_curr = 57\n",
    "                Gross_curr = 9\n",
    "                Grip_curr = 12\n",
    "                GraPinch_curr = 36\n",
    "                synergy_curr = 36\n",
    "                zone_time_nt.append(df_icosahedronSummary[subject][zone])\n",
    "            fmue_scores.append(fmue_curr)\n",
    "            arat_scores.append(arat_curr)\n",
    "            arat_Gross.append(Gross_curr)\n",
    "            arat_Grip.append(Grip_curr)\n",
    "            arat_GraPinch.append(GraPinch_curr)\n",
    "            fmue_synergy.append(synergy_curr)\n",
    "            #Find the percenttime in this zone\n",
    "            percent_curr = df_icosahedronSummary[subject][zone]\n",
    "            percent_time.append(percent_curr)\n",
    "    #color='rgb({}, {}, {})'.format(np.random.randint(0, 192), np.random.randint(0, 192), np.random.randint(0, 192))\n",
    "    colors = ['#33a02c', '#ff7f00', '#6a3d9a', '#b15928', '#e377c2', '#bcbd22', '#17becf', '#FF0000', '#000000', '#7f7f7f']\n",
    "    #print('fmue_scores', fmue_scores)\n",
    "    #print('percent time', percent_time)\n",
    "    \n",
    "    percent_time = np.array(percent_time)\n",
    "    fmue_scores = np.array(fmue_scores)\n",
    "    arat_scores = np.array(arat_scores)\n",
    "    arat_Gross = np.array(arat_Gross)\n",
    "    arat_Grip = np.array(arat_Grip)\n",
    "    arat_GraPinch = np.array(arat_GraPinch)\n",
    "    fmue_synergy = np.array(fmue_synergy)\n",
    "    fmue_other = fmue_scores - fmue_synergy\n",
    "    zone_time_ss = np.array(zone_time_ss)\n",
    "    zone_time_nt = np.array(zone_time_nt)\n",
    "    print(fmue_synergy)\n",
    "\n",
    "    linearRegression(fmue_scores, percent_time, zone, fig100, '% Time Icosahedron v FMUE', color_count)\n",
    "    linearRegression(arat_scores, percent_time, zone, figarat, '% Time Icosahedron v ARAT', color_count)\n",
    "    linearRegression(arat_Gross, percent_time, zone, figGross, '% Time Icos v Gross Arat Subscore', color_count)\n",
    "    linearRegression(arat_Grip, percent_time, zone, figGrip, '% Time Icos v Grip Arat Subscore', color_count)\n",
    "    linearRegression(arat_GraPinch, percent_time, zone, figGraPinch, '% Time Icos v GraspPinch Arat Subscore', color_count)\n",
    "    linearRegression(fmue_synergy, percent_time, zone, figSynergy, '% Time Icos v Synergy FMUE Subscore', color_count)            \n",
    "    linearRegression(fmue_other, percent_time, zone, figOther, '% Time Icos v Gross FMUE Subscore', color_count)   \n",
    "    color_count +=1\n",
    "\n",
    "    t_stat, p_value = ttest_ind(zone_time_nt, zone_time_ss, equal_var=False)\n",
    "    if p_value < 0.05:\n",
    "        ttest_results_per_zone.append({'Zone': zone+1, 'p_val': p_value, 'Mean Stroke': np.mean(zone_time_ss), 'Mean NT': np.mean(zone_time_nt)})\n",
    "\n",
    "# add legend\n",
    "fig100.update_layout(\n",
    "    legend=dict(\n",
    "        #orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    ),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    xaxis_title='FMUE Scores',\n",
    "    yaxis_title='Percent Time Spent in Zone (%)',\n",
    "    title='Icosahedron Regression'\n",
    ")\n",
    "fig100.show()\n",
    "figarat.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1), title='Arat Regression')\n",
    "figarat.show()\n",
    "figGross.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1), title='Arat Gross Subscore Regression')\n",
    "figGross.show()\n",
    "figGrip.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1), title='Arat Grip Subscore Regression')\n",
    "figGrip.show()\n",
    "figGraPinch.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1), title='Arat Grasp/Pinch Subscore Regression')\n",
    "figGraPinch.show()\n",
    "figSynergy.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1), title='FMUE synergy Subscore Regression')\n",
    "figSynergy.show()\n",
    "figOther.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1), title='FMUE Gross Subscore Regression')\n",
    "figOther.show()\n",
    "\n",
    "\n",
    "#add a super small constant to 0s to avoid log issues\n",
    "tiny_constant = 1e-6\n",
    "\n",
    "# Check the variability per Icosahedron zone of the neurotypicals\n",
    "s_columns = [col for col in df_icosahedronSummary.columns if col.startswith('s')]\n",
    "p_columns = [col for col in df_icosahedronSummary.columns if col.startswith('p')]\n",
    "\n",
    "#print(s_columns)\n",
    "\n",
    "# Create a DataFrame to store CI results\n",
    "ci_results = []\n",
    "\n",
    "# Iterate over each row to calculate confidence intervals\n",
    "for index, row in df_icosahedronSummary.iterrows():\n",
    "    s_values = row[s_columns].dropna()\n",
    "    s_values = s_values / 100 #switch to probability from percentage\n",
    "    mean = np.mean(s_values)\n",
    "    sem = stats.sem(s_values)\n",
    "    ci = stats.t.interval(0.95, len(s_values)-1, loc=mean, scale=sem)\n",
    "    \n",
    "    ci_lower = max(ci[0], tiny_constant)\n",
    "    \n",
    "    ci_results.append({\n",
    "        'Zone': f'Zone {index+1}',\n",
    "        'CI Lower': ci_lower,\n",
    "        'CI Upper': ci[1],\n",
    "        'Mean': mean\n",
    "    })\n",
    "    \n",
    "#print(ci_results)\n",
    "\n",
    "# Initialize a dictionary to store the count of p_columns outside CI\n",
    "ci_df = pd.DataFrame(ci_results)\n",
    "outside_counts = {p_col: 0 for p_col in p_columns}\n",
    "outsideCI_perzone = {zone: 0 for zone in range(len(df_icosahedronSummary))}\n",
    "outsideCI_direction = {zone: {p_col: None for p_col in p_columns} for zone in range(len(df_icosahedronSummary))}\n",
    "\n",
    "\n",
    "# Check if p_column values are outside CI\n",
    "for index, row in df_icosahedronSummary.iterrows():\n",
    "    zone = f'Zone {index + 1}'\n",
    "    ci_row= ci_df[ci_df['Zone'] == zone].iloc[0]\n",
    "    \n",
    "    ci_lower = ci_row['CI Lower']\n",
    "    ci_upper = ci_row['CI Upper']\n",
    "    \n",
    "    if not pd.isna(ci_lower) and not pd.isna(ci_upper):\n",
    "        for p_col in p_columns:\n",
    "            p_value = row[p_col] / 100 + tiny_constant\n",
    "            if p_value < ci_lower:\n",
    "                # Value is below the lower CI bound\n",
    "                outside_counts[p_col] += 1\n",
    "                outsideCI_perzone[index] += 1\n",
    "                outsideCI_direction[index][p_col] = 'Lower'\n",
    "            \n",
    "            elif p_value > ci_upper:\n",
    "                # Value is above the upper CI bound\n",
    "                outside_counts[p_col] += 1\n",
    "                outsideCI_perzone[index] += 1\n",
    "                outsideCI_direction[index][p_col] = 'Higher'\n",
    "            \n",
    "            else:\n",
    "                # Value is within the CI bounds\n",
    "                outsideCI_direction[index][p_col] = 'Within'\n",
    "                #print(f'{p_col}: {p_value} is outside {ci_lower} to {ci_upper}')\n",
    "nt_ci_data = ci_results\n",
    "print(f'Plotting icosahedron based on OutsideCIPerZone {outsideCI_perzone}')\n",
    "\n",
    "counts_icos = []\n",
    "# Print the counts of p_columns outside CI\n",
    "for p_col, count in outside_counts.items():\n",
    "    print(f'{p_col} is outside the confidence intervals in {count} zones.')\n",
    "    counts_icos.append(count)\n",
    "\n",
    "\n",
    "colors = sns.color_palette(\"husl\", len(p_columns))  # Husl generates a distinct color palette\n",
    "p_color_map = {col: colors[i] for i, col in enumerate(p_columns)}\n",
    "\n",
    "plot_data = pd.DataFrame()\n",
    "for index, zone in df_icosahedronSummary.iterrows():\n",
    "    s_zone_data = zone[s_columns].dropna() /100 #convert back to probability instead of %\n",
    "    p_zone_data = zone[p_columns].dropna() / 100\n",
    "    \n",
    "    #add the tiny constant to the values\n",
    "    s_zone_data = s_zone_data.astype('float') + tiny_constant\n",
    "    p_zone_data = p_zone_data.astype('float') + tiny_constant\n",
    "\n",
    "    s_temp_df = pd.DataFrame({\n",
    "        'Values': s_zone_data.values,\n",
    "        'Zone': zone['Zones'] if 'Zone' in df_icosahedronSummary.columns else f'{index+1}',\n",
    "        'Type': 's',\n",
    "        'Color': 'black',\n",
    "        'Subject': 'Neurotypicals'\n",
    "    })\n",
    "    \n",
    "    p_temp_df = pd.DataFrame({\n",
    "        'Values': p_zone_data.values,\n",
    "        'Zone': zone['Zones'] if 'Zone' in df_icosahedronSummary.columns else f'{index+1}',\n",
    "        'Type': 'p',\n",
    "        'Color': [p_color_map[col] for col in p_zone_data.index], #assign colors\n",
    "        'Subject': p_zone_data.index\n",
    "    })\n",
    "    \n",
    "    plot_data = pd.concat([plot_data, s_temp_df, p_temp_df], axis=0)\n",
    "    \n",
    "#plot box and whisker plot\n",
    "plt.figure(figsize=(12,8), dpi=600)\n",
    "stripplot = sns.stripplot(x='Zone', y='Values', data=plot_data, hue='Subject', palette={'Neurotypicals': 'black', **p_color_map}, size=5, jitter=True, dodge=True)\n",
    "s_coords = stripplot.collections[0].get_offsets()[:, 0]\n",
    "for idx, ci in ci_df.iterrows():\n",
    "    #x_coord = s_coords[idx]\n",
    "    plt.scatter(idx-0.4, ci['Mean'], edgecolor='black', facecolor='white', s=20, zorder=5)\n",
    "    print([ci['CI Lower'], ci['CI Upper']])\n",
    "    plt.errorbar(x=idx-0.4, y=ci['Mean'], yerr=[[ci['Mean'] - ci['CI Lower']], [ci['CI Upper'] - ci['Mean']]],\n",
    "                 fmt='o', color='black', capsize=5)\n",
    "\n",
    "plt.title(f'Wrist Position Probability in Icosahedron-based Zones')  # Assuming there's a column named 'Area'\n",
    "plt.xlabel('Zones (1-40)')\n",
    "plt.ylabel('Probability ')\n",
    "plt.yscale('log')\n",
    "plt.ylim(8e-7, 1e0) #ignore the 0s\n",
    "plt.legend(title='Subject', loc='upper left', bbox_to_anchor=(1, 1), borderaxespad=0.)\n",
    "\n",
    "# Setting black outlines for boxes and whiskers\n",
    "#for patch in plt.gca().artists:\n",
    " #   patch.set_edgecolor('black')\n",
    "  #  patch.set_linewidth(1.5)\n",
    "\n",
    "# Display plot\n",
    "plt.show()\n",
    "\n",
    "#Cumulative distribution for icosahedron\n",
    "mean_values = ci_df[['Zone', 'Mean']].copy() #store the mean_values of the nt group\n",
    "zones_sorted = mean_values.sort_values(by='Mean', ascending=False)\n",
    "zones_sorted['Cumulative Sum'] = zones_sorted['Mean'].cumsum()\n",
    "\n",
    "uniform_zones = np.linspace(0.05, 1, len(zones_sorted))\n",
    "\n",
    "# Step 4: Plot the cumulative distribution\n",
    "plt.figure(figsize=(10, 6), dpi=600)\n",
    "sns.lineplot(x=zones_sorted['Zone'], y=zones_sorted['Cumulative Sum'], color='black', label = 'Neurotypical')\n",
    "sns.lineplot(x=zones_sorted['Zone'], y=uniform_zones, marker='o', color='brown', linestyle='--', label='Uniform')\n",
    "\n",
    "# Plot cumulative distribution for s_columns\n",
    "#for s_col in s_columns:\n",
    " #   s_sorted = df_icosahedronSummary[s_col].dropna().sort_values(ascending=False)\n",
    "  #  s_cumsum = s_sorted.cumsum() / 100\n",
    "   # sns.lineplot(x=range(len(s_sorted)), y=s_cumsum, marker='o', label=f'Cumulative Sum ({s_col})', color='black')\n",
    "\n",
    "\n",
    "# Step 4: Calculate cumulative sums for p_columns based on the sorted order of s_columns\n",
    "for p_col in p_columns:\n",
    "    #p_sorted = df_icosahedronSummary[p_col].dropna().sort_values(ascending=False)\n",
    "    #p_cumsum = p_sorted.cumsum()/ 100\n",
    "    p_data_sorted = df_icosahedronSummary.loc[zones_sorted.index, p_col].dropna().cumsum() / 100\n",
    "    sns.lineplot(x=zones_sorted['Zone'], y=p_data_sorted.values, marker='o', linestyle='--', label=f'({p_col})', color=p_color_map[p_col])\n",
    "    #sns.lineplot(x=range(len(p_sorted)), y=p_cumsum, marker='o', label=f'{p_col}', color=p_color_map[p_col])\n",
    "# Customizing the plot\n",
    "plt.title('Cumulative Probability Distribution by Icosahedron Zone')\n",
    "plt.xlabel('Zones Ordered by Tendency')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "#Create a grid - heatmap to show the different plots\n",
    "zones = list(range(1, len(mean_values)+1))  # 40 zones\n",
    "\n",
    "# Prepare an empty 20x20 grid\n",
    "heatmap_data = np.zeros((20, len(mean_values)))  # 20 individuals, 20 zones\n",
    "heatmap_data[0, 0:len(mean_values)] = mean_values['Mean'] - mean_values['Mean']\n",
    "\n",
    "# Create a DataFrame with the same structure\n",
    "for index, zone in df_icosahedronSummary.iterrows():\n",
    "    p_zone_data = zone[p_columns].dropna() / 100  # Convert back to probability instead of %\n",
    "    \n",
    "    # Subtract the mean from each individual's data\n",
    "    mean_value = mean_values['Mean'][index]  # Get the mean value for this zone\n",
    "    heatmap_data[1:, index] = p_zone_data - mean_value  # Store the difference\n",
    "\n",
    "icos_strk_data = p_zone_data\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8), dpi=300)\n",
    "\n",
    "# Option 1 - vertical layering\n",
    "order = [8, 2, 5, 3, 4, 1, 7, 6, 19, 17, 12, 9, 15, 14, 16, 10, 13, 11, 18, 20, 28, 22, 25, 23, 24, 21, 27, 26, 39, 37, 32, 29, 35, 34, 36, 30, 33, 31, 38, 40]\n",
    "\n",
    "#option 2 - horizontal layering\n",
    "order = [5, 3, 4, 17, 12, 11, 13, 18, 2, 1, 7, 19, 9, 10, 20, 8, 6, 15, 14, 16]\n",
    "\n",
    "# option 3 - poster-> anterior hamiltonian\n",
    "order = [8, 2, 5, 3, 4, 1, 6, 7, 19, 17, 12, 11, 13, 10, 9, 15, 14, 16, 20, 18, 28, 22, 25, 23, 24, 21, 26, 27, 39, 37, 32, 31, 33, 30, 29, 35, 34, 36, 40, 38]\n",
    "order_cols = np.array(order) - 1\n",
    "\n",
    "#organize the subjects by FMUE score\n",
    "index_nt = np.where(fmue_scores == 66)[0][0]\n",
    "sorted_subj = np.argsort(-fmue_scores[:index_nt])\n",
    "print(f\"Sorted order of subjects: {sorted_subj}\")\n",
    "sorted_idx = np.array(sorted_subj) + 1\n",
    "order_rows = np.insert(sorted_idx, 0, 0)\n",
    "\n",
    "heatmap_temp = heatmap_data[order_rows, :]\n",
    "heatmap_plot = heatmap_temp[:, order_cols]\n",
    "\n",
    "# Create a custom colormap based on 'coolwarm' but with white at the center (0)\n",
    "coolwarm_custom = LinearSegmentedColormap.from_list('coolwarm_custom', ['blue', 'white', 'red'])\n",
    "\n",
    "# Create a color map where negative values are blue, positive are red, and zero is white\n",
    "sns.heatmap(heatmap_plot, cmap=coolwarm_custom, center=0, annot=False, linewidths=0.5, xticklabels=range(1, 41))\n",
    "\n",
    "# Set plot titles and labels\n",
    "plt.title('Heatmap of Upper Extremity Movements (Difference from Mean Neurotypical)')\n",
    "plt.xlabel('Zones (1-40)')\n",
    "plt.ylabel('Individuals (1-20)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "#calculate overall stroke group difference array\n",
    "heatDifference_icosahedron = np.mean(heatmap_temp[-19:, :], axis=0)\n",
    "\n",
    "\n",
    "#Weakness identification\n",
    "ci_results\n",
    "\n",
    "# RECTILINEAR NOW\n",
    "\n",
    "#ICOSAHEDRON % TIME Wrist Position - Linear Regression\n",
    "df_rectilinearSummary = pd.read_excel('/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/StatisticsCollection/ZoneDistribution_Rectilinear.xlsx')\n",
    "clinical_df = pd.read_csv('/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/ClinicalFiles/phase1_clinicalscores.csv')\n",
    "clinical_aratBreakdown = pd.read_csv('/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/ClinicalFiles/ExoNETPhase1-AllDataNoPHI_DATA_LABELS_2024-07-22_1711.csv')\n",
    "directory = '/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/'\n",
    "#parse through the directory, go through each csv file\n",
    "fig100 = go.Figure()\n",
    "figarat = go.Figure()\n",
    "figGross = go.Figure()\n",
    "figGrip = go.Figure()\n",
    "figGraPinch = go.Figure()\n",
    "figSynergy = go.Figure()\n",
    "figOther = go.Figure()\n",
    "color_count = 0\n",
    "ttest_results_per_zone = []\n",
    "for zone in range(27):\n",
    "    percent_time = []\n",
    "    arat_scores = []\n",
    "    fmue_scores = []\n",
    "    arat_Gross = []\n",
    "    arat_Grip = []\n",
    "    arat_GraPinch = []\n",
    "    fmue_synergy = []\n",
    "    zone_time_ss = []\n",
    "    zone_time_nt = []\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath) and not fnmatch.fnmatch(filename, '.DS_Store'):\n",
    "            ind = filename.find('_')\n",
    "            subject = filename[:ind]\n",
    "            if subject[0] == 'p':\n",
    "                fmue_curr = clinical_df[(clinical_df['subject'].str.lower() == subject) & (clinical_df['session'].str.lower() == 'baseline')]['fmue']\n",
    "                arat_curr = clinical_df[(clinical_df['subject'].str.lower() == subject) & (clinical_df['session'].str.lower() == 'baseline')]['arat']\n",
    "                ARATbreakdown_curr = clinical_aratBreakdown[(clinical_aratBreakdown['Record ID'].str.lower() == subject) & (clinical_aratBreakdown['Event Name'].str.lower() == 'baseline evals')]\n",
    "                Synergylist_backup = clinical_aratBreakdown[(clinical_aratBreakdown['Record ID'].str.lower() == subject) & (clinical_aratBreakdown['Event Name'].str.lower() == 'screening')]\n",
    "                Gross_curr = int(ARATbreakdown_curr['Gross Movement Total Score'])\n",
    "                Grip_curr = int(ARATbreakdown_curr['Grip Subtest Total Score'])\n",
    "                GraPinch_curr = [int(ARATbreakdown_curr['Grasp Subtest Total Score']), int(ARATbreakdown_curr['Pinch Subtest Total Score'])]\n",
    "                GraPinch_curr = np.sum(GraPinch_curr)\n",
    "                fmue_curr = int(fmue_curr)\n",
    "                arat_curr = int(arat_curr)\n",
    "                if ARATbreakdown_curr['Biceps- Flexor'].isna().any():\n",
    "                    synergy_list = [int(Synergylist_backup['Biceps- Flexor']), int(Synergylist_backup['Triceps - Extensor']), int(Synergylist_backup['Elevation']), int(Synergylist_backup['Retraction']), int(Synergylist_backup['Abduction']), int(Synergylist_backup['External Rotation']), int(Synergylist_backup['Elbow Flexion']), int(Synergylist_backup['Supination']), int(Synergylist_backup['Abduction']), int(Synergylist_backup['Adduction/Internal Rotation']), int(Synergylist_backup['Elbow Extension']), int(Synergylist_backup['Pronation']), int(Synergylist_backup['Hand to Lumbar Spine']), int(Synergylist_backup['Shoulder flexion to 90 degrees with elbow at 0 degrees and forearm in neutral']), int(Synergylist_backup['Pronation/Supination with elbow at 90 degrees']), int(Synergylist_backup['Abduction to 90 degrees']), int(Synergylist_backup['Shoulder flexion 90 to 180 degrees with elbow at 0 degrees and forearm in neutral']), int(Synergylist_backup['Pronation/Supination with elbow at 0 degrees and shoulder flexed 30 to 90 degrees']), int(Synergylist_backup['Test deep tendon relfexes of the biceps OR long finger flexors, then triceps'])]\n",
    "                else:\n",
    "                    synergy_list = [int(ARATbreakdown_curr['Biceps- Flexor']), int(ARATbreakdown_curr['Triceps - Extensor']), int(ARATbreakdown_curr['Elevation']), int(ARATbreakdown_curr['Retraction']), int(ARATbreakdown_curr['Abduction']), int(ARATbreakdown_curr['External Rotation']), int(ARATbreakdown_curr['Elbow Flexion']), int(ARATbreakdown_curr['Supination']), int(ARATbreakdown_curr['Abduction']), int(ARATbreakdown_curr['Adduction/Internal Rotation']), int(ARATbreakdown_curr['Elbow Extension']), int(ARATbreakdown_curr['Pronation']), int(ARATbreakdown_curr['Hand to Lumbar Spine']), int(ARATbreakdown_curr['Shoulder flexion to 90 degrees with elbow at 0 degrees and forearm in neutral']), int(ARATbreakdown_curr['Pronation/Supination with elbow at 90 degrees']), int(ARATbreakdown_curr['Abduction to 90 degrees']), int(ARATbreakdown_curr['Shoulder flexion 90 to 180 degrees with elbow at 0 degrees and forearm in neutral']), int(ARATbreakdown_curr['Pronation/Supination with elbow at 0 degrees and shoulder flexed 30 to 90 degrees']), int(ARATbreakdown_curr['Test deep tendon relfexes of the biceps OR long finger flexors, then triceps'])]\n",
    "                synergy_curr = np.sum(synergy_list)\n",
    "                zone_time_ss.append(df_rectilinearSummary[subject][zone])\n",
    "            else:\n",
    "                fmue_curr = 66\n",
    "                arat_curr = 57\n",
    "                Gross_curr = 9\n",
    "                Grip_curr = 12\n",
    "                GraPinch_curr = 36\n",
    "                synergy_curr = 36\n",
    "                zone_time_nt.append(df_icosahedronSummary[subject][zone])\n",
    "            fmue_scores.append(fmue_curr)\n",
    "            arat_scores.append(arat_curr)\n",
    "            arat_Gross.append(Gross_curr)\n",
    "            arat_Grip.append(Grip_curr)\n",
    "            arat_GraPinch.append(GraPinch_curr)\n",
    "            fmue_synergy.append(synergy_curr)\n",
    "            #Find the percenttime in this zone\n",
    "            percent_curr = df_rectilinearSummary[subject][zone]\n",
    "            percent_time.append(percent_curr)\n",
    "    #color='rgb({}, {}, {})'.format(np.random.randint(0, 192), np.random.randint(0, 192), np.random.randint(0, 192))\n",
    "    colors = ['#33a02c', '#ff7f00', '#6a3d9a', '#b15928', '#e377c2', '#bcbd22', '#17becf', '#FF0000', '#000000', '#7f7f7f']\n",
    "    #print('fmue_scores', fmue_scores)\n",
    "    #print('percent time', percent_time)\n",
    "    \n",
    "    percent_time = np.array(percent_time)\n",
    "    fmue_scores = np.array(fmue_scores)\n",
    "    arat_scores = np.array(arat_scores)\n",
    "    arat_Gross = np.array(arat_Gross)\n",
    "    arat_Grip = np.array(arat_Grip)\n",
    "    arat_GraPinch = np.array(arat_GraPinch)\n",
    "    fmue_synergy = np.array(fmue_synergy)\n",
    "    fmue_other = fmue_scores - fmue_synergy\n",
    "    zone_time_ss = np.array(zone_time_ss)\n",
    "    zone_time_nt = np.array(zone_time_nt)\n",
    "    print(fmue_synergy)\n",
    "\n",
    "    linearRegression(fmue_scores, percent_time, zone, fig100, '% Time Rectilinear v FMUE', color_count)\n",
    "    linearRegression(arat_scores, percent_time, zone, figarat, '% Time Rectilinear v ARAT', color_count)\n",
    "    linearRegression(arat_Gross, percent_time, zone, figGross, '% Time Rectilinear v Gross Arat Subscore', color_count)\n",
    "    linearRegression(arat_Grip, percent_time, zone, figGrip, '% Time Rectilinear v Grip Arat Subscore', color_count)\n",
    "    linearRegression(arat_GraPinch, percent_time, zone, figGraPinch, '% Time Rectilinear v GraspPinch Arat Subscore', color_count)\n",
    "    linearRegression(fmue_synergy, percent_time, zone, figSynergy, '% Time Rectilinear v Synergy FMUE Subscore', color_count)            \n",
    "    linearRegression(fmue_other, percent_time, zone, figOther, '% Time Rectilinear v Gross FMUE Subscore', color_count)   \n",
    "    color_count +=1\n",
    "\n",
    "    t_stat, p_value = ttest_ind(zone_time_nt, zone_time_ss, equal_var=False)\n",
    "    if p_value < 0.05:\n",
    "        ttest_results_per_zone.append({'Zone': zone+1, 'p_val': p_value, 'Mean Stroke': np.mean(zone_time_ss), 'Mean NT': np.mean(zone_time_nt)})\n",
    "\n",
    "# add legend\n",
    "fig100.update_layout(\n",
    "    legend=dict(\n",
    "        #orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    ),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    xaxis_title='FMUE Scores',\n",
    "    yaxis_title='Percent Time Spent in Zone (%)',\n",
    "    title='Rectilinear Regression'\n",
    ")\n",
    "fig100.show()\n",
    "figarat.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1), title='Arat Regression')\n",
    "figarat.show()\n",
    "figGross.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1), title='Arat Gross Subscore Regression')\n",
    "figGross.show()\n",
    "figGrip.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1), title='Arat Grip Subscore Regression')\n",
    "figGrip.show()\n",
    "figGraPinch.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1), title='Arat Grasp/Pinch Subscore Regression')\n",
    "figGraPinch.show()\n",
    "figSynergy.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1), title='FMUE synergy Subscore Regression')\n",
    "figSynergy.show()\n",
    "figOther.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1), title='FMUE Gross Subscore Regression')\n",
    "figOther.show()\n",
    "\n",
    "# Check the variability per Rectilinear zone of the neurotypicals\n",
    "s_columns = [col for col in df_rectilinearSummary.columns if col.startswith('s')]\n",
    "p_columns = [col for col in df_rectilinearSummary.columns if col.startswith('p')]\n",
    "\n",
    "\n",
    "# Create a DataFrame to store CI results\n",
    "ci_results = []\n",
    "\n",
    "# Iterate over each row to calculate confidence intervals\n",
    "for index, row in df_rectilinearSummary.iterrows():\n",
    "    s_values = row[s_columns].dropna()\n",
    "    s_values = s_values / 100\n",
    "    mean = np.mean(s_values)\n",
    "    sem = stats.sem(s_values)\n",
    "    ci = stats.t.interval(0.95, len(s_values)-1, loc=mean, scale=sem)\n",
    "    \n",
    "    ci_lower = max(ci[0], tiny_constant)\n",
    "    \n",
    "    ci_results.append({\n",
    "        'Zone': f'Zone {index+1}',\n",
    "        'CI Lower': ci_lower,\n",
    "        'CI Upper': ci[1],\n",
    "        'Mean': mean\n",
    "    })\n",
    "    \n",
    "print(ci_results)\n",
    "\n",
    "# Initialize a dictionary to store the count of p_columns outside CI\n",
    "ci_df = pd.DataFrame(ci_results)\n",
    "Rect_outside_counts = {p_col: 0 for p_col in p_columns}\n",
    "Rect_outsideCI_perzone = {zone: 0 for zone in range(len(df_rectilinearSummary))}\n",
    "Rect_outsideCI_direction = {zone: {p_col: None for p_col in p_columns} for zone in range(len(df_rectilinearSummary))}\n",
    "\n",
    "\n",
    "# Check if p_column values are outside CI\n",
    "for index, row in df_rectilinearSummary.iterrows():\n",
    "    zone = f'Zone {index + 1}'\n",
    "    ci_row= ci_df[ci_df['Zone'] == zone].iloc[0]\n",
    "    \n",
    "    ci_lower = ci_row['CI Lower']\n",
    "    ci_upper = ci_row['CI Upper']\n",
    "    \n",
    "    if not pd.isna(ci_lower) and not pd.isna(ci_upper):\n",
    "        for p_col in p_columns:\n",
    "            p_value = row[p_col] / 100 + tiny_constant\n",
    "            if p_value < ci_lower:\n",
    "                # Value is below the lower CI bound\n",
    "                Rect_outside_counts[p_col] += 1\n",
    "                Rect_outsideCI_perzone[index] += 1\n",
    "                Rect_outsideCI_direction[index][p_col] = 'Lower'\n",
    "            \n",
    "            elif p_value > ci_upper:\n",
    "                # Value is above the upper CI bound\n",
    "                Rect_outside_counts[p_col] += 1\n",
    "                Rect_outsideCI_perzone[index] += 1\n",
    "                Rect_outsideCI_direction[index][p_col] = 'Higher'\n",
    "            \n",
    "            else:\n",
    "                # Value is within the CI bounds\n",
    "                Rect_outsideCI_direction[index][p_col] = 'Within'\n",
    "                #print(f'{p_col}: {p_value} is outside {ci_lower} to {ci_upper}')\n",
    "Rect_nt_ci_data = ci_results\n",
    "print(f'Plotting Rectilinear based on OutsideCIPerZone {Rect_outsideCI_perzone}')\n",
    "\n",
    "# Print the counts of p_columns outside CI\n",
    "counts_rect = []\n",
    "for p_col, count in outside_counts.items():\n",
    "    print(f'{p_col} is outside the confidence intervals in {count} zones.')\n",
    "    counts_rect.append(count)\n",
    "\n",
    "colors = sns.color_palette(\"husl\", len(p_columns))  # Husl generates a distinct color palette\n",
    "p_color_map = {col: colors[i] for i, col in enumerate(p_columns)}\n",
    "\n",
    "plot_data = pd.DataFrame()\n",
    "for index, zone in df_rectilinearSummary.iterrows():\n",
    "    s_zone_data = zone[s_columns].dropna() / 100 # convert back to probability instead of %\n",
    "    p_zone_data = zone[p_columns].dropna() / 100\n",
    "    \n",
    "    #add the tiny constant to the values\n",
    "    s_zone_data = s_zone_data.astype('float') + tiny_constant\n",
    "    p_zone_data = p_zone_data.astype('float') + tiny_constant\n",
    "    \n",
    "    s_temp_df = pd.DataFrame({\n",
    "        'Values': s_zone_data.values,\n",
    "        'Zone': zone['Zones'] if 'Zone' in df_rectilinearSummary.columns else f'{index+1}',\n",
    "        'Type': 's',\n",
    "        'Color': 'black',\n",
    "        'Subject': 'Neurotypicals'\n",
    "    })\n",
    "    \n",
    "    p_temp_df = pd.DataFrame({\n",
    "        'Values': p_zone_data.values,\n",
    "        'Zone': zone['Zones'] if 'Zone' in df_rectilinearSummary.columns else f'{index+1}',\n",
    "        'Type': 'p',\n",
    "        'Color': [p_color_map[col] for col in p_zone_data.index], #assign colors\n",
    "        'Subject': p_zone_data.index\n",
    "    })\n",
    "    \n",
    "    plot_data = pd.concat([plot_data, s_temp_df, p_temp_df], axis=0)\n",
    "\n",
    "# Create a DataFrame that has the diff of stroke survivors to the mean values for each zone\n",
    "stroke_df = df_rectilinearSummary[p_columns]\n",
    "stroke_diff_df = stroke_df.copy()\n",
    "print(stroke_df)\n",
    "for i in range(27):\n",
    "    mean_val = Rect_nt_ci_data[i]['Mean']  # Assuming Rect_nt_ci_data is a DataFrame or Series\n",
    "    print(mean_val)\n",
    "    stroke_diff_df.iloc[i] = (stroke_df.iloc[i] / 100).subtract(mean_val, axis=0)\n",
    "\n",
    "#plot box and whisker plot\n",
    "plt.figure(figsize=(12,8), dpi=600)\n",
    "stripplot = sns.stripplot(x='Zone', y='Values', data=plot_data, hue='Subject', palette={'Neurotypicals': 'black', **p_color_map}, size=5, jitter=True, dodge=True)\n",
    "s_coords = stripplot.collections[0].get_offsets()[:, 0]\n",
    "for idx, ci in ci_df.iterrows():\n",
    "    #x_coord = s_coords[idx]\n",
    "    plt.scatter(idx-0.4, ci['Mean'], edgecolor='black', facecolor='white', s=20, zorder=5)\n",
    "    plt.errorbar(x=idx-0.4, y=ci['Mean'], yerr=[[ci['Mean'] - ci['CI Lower']], [ci['CI Upper'] - ci['Mean']]],\n",
    "                 fmt='o', color='black', capsize=5)\n",
    "\n",
    "\n",
    "\n",
    "plt.title(f'Wrist Position Probability in Rectilinear-based Zones')  # Assuming there's a column named 'Area'\n",
    "plt.xlabel('Zones (1-27)')\n",
    "plt.ylabel('Probability')\n",
    "plt.yscale('log')\n",
    "plt.ylim(8e-7, 1e0) #ignore the 0s\n",
    "plt.legend(title='Subject', loc='upper left', bbox_to_anchor=(1, 1), borderaxespad=0.)\n",
    "\n",
    "# Setting black outlines for boxes and whiskers\n",
    "#for patch in plt.gca().artists:\n",
    " #   patch.set_edgecolor('black')\n",
    "  #  patch.set_linewidth(1.5)\n",
    "\n",
    "# Display plot\n",
    "plt.show()\n",
    "\n",
    "#plot the cumulative distribution curve for the NT mean in black\n",
    "# stroke can have the same colors but lines \n",
    "mean_values = ci_df[['Zone', 'Mean']].copy()\n",
    "zones_sorted = mean_values.sort_values(by='Mean', ascending=False)\n",
    "zones_sorted['Cumulative Sum'] = zones_sorted['Mean'].cumsum()\n",
    "\n",
    "uniform_zones = np.linspace(0.05, 1, len(zones_sorted))\n",
    "\n",
    "# Step 4: Plot the cumulative distribution\n",
    "plt.figure(figsize=(10, 6), dpi=600)\n",
    "sns.lineplot(x=zones_sorted['Zone'], y=zones_sorted['Cumulative Sum'], marker='o', color='black', label = 'Neurotypical')\n",
    "sns.lineplot(x=zones_sorted['Zone'], y=uniform_zones, color='brown', linestyle='--', label='Uniform')\n",
    "\n",
    "# Step 4: Calculate cumulative sums for p_columns based on the sorted order of s_columns\n",
    "for p_col in p_columns:\n",
    "    #p_sorted = df_rectilinearSummary[p_col].dropna().sort_values(ascending=False)\n",
    "    #p_cumsum = p_sorted.cumsum()/ 100\n",
    "    p_data_sorted = df_rectilinearSummary.loc[zones_sorted.index, p_col].dropna().cumsum() / 100\n",
    "    sns.lineplot(x=zones_sorted['Zone'], y=p_data_sorted.values, marker='o', linestyle='--', label=f'({p_col})', color=p_color_map[p_col])\n",
    "    #sns.lineplot(x=range(len(p_sorted)), y=p_cumsum, marker='o', label=f'{p_col}', color=p_color_map[p_col])\n",
    "# Customizing the plot\n",
    "plt.title('Cumulative Probability Distribution by Rectilinear Zone')\n",
    "plt.xlabel('Zones Ordered by Tendency')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "#3D plots\n",
    "df = pd.read_csv('/Users/adithsrivatsa/Desktop/SphericalDistributionAnalysis/s06_freexp_control.csv')\n",
    "\n",
    "subject = 's06'\n",
    "rightDomList = ['s04', 's06', 's08', 's10', 's11', 's12', 's14', 'p01', 'p03', 'p10', 'p12', 'p13', 'p17', 'p33', 'p37']\n",
    "right = 1\n",
    "\n",
    "if subject in rightDomList:\n",
    "    right = 1\n",
    "else:\n",
    "    right = 0\n",
    "    \n",
    "if right == 1: \n",
    "    shoulder_cols = ['ShoulderRight_X', 'ShoulderRight_Y', 'ShoulderRight_Z']\n",
    "    wrist_cols = ['WristRight_X', 'WristRight_Y', 'WristRight_Z']\n",
    "else:\n",
    "    shoulder_cols = ['ShoulderLeft_X', 'ShoulderLeft_Y', 'ShoulderLeft_Z']\n",
    "    wrist_cols = ['WristLeft_X', 'WristLeft_Y', 'WristLeft_Z']\n",
    "\n",
    "#Normalize to shoulder\n",
    "center = df[shoulder_cols].loc[:100, :].mean()\n",
    "center.astype(np.int64)\n",
    "df.dropna(subset = wrist_cols)\n",
    "if right == 1:\n",
    "    df['Wrist_X'] = df['WristRight_X'] - center['ShoulderRight_X']\n",
    "    df['Wrist_Y'] = df['WristRight_Y'] - center['ShoulderRight_Y']\n",
    "    df['Wrist_Z'] = df['WristRight_Z'] - center['ShoulderRight_Z']\n",
    "    df['Hip_X'] = df['HipRight_X'] - center['ShoulderRight_X']\n",
    "    df['Hip_Y'] = df['HipRight_Y'] - center['ShoulderRight_Y']\n",
    "    df['Hip_Z'] = df['HipRight_Z'] - center['ShoulderRight_Z']\n",
    "    df['Elbow_X'] = df['ElbowRight_X'] - center['ShoulderRight_X']\n",
    "    df['Elbow_Y'] = df['ElbowRight_Y'] - center['ShoulderRight_Y']\n",
    "    df['Elbow_Z'] = df['ElbowRight_Z'] - center['ShoulderRight_Z']\n",
    "    df['Hand_X'] = df['HandRight_X'] - center['ShoulderRight_X']\n",
    "    df['Hand_Y'] = df['HandRight_Y'] - center['ShoulderRight_Y']\n",
    "    df['Hand_Z'] = df['HandRight_Z'] - center['ShoulderRight_Z']\n",
    "    df['Shoulder_X'] = df['ShoulderRight_X'] - center['ShoulderRight_X']\n",
    "    df['Shoulder_Y'] = df['ShoulderRight_Y'] - center['ShoulderRight_Y']\n",
    "    df['Shoulder_Z'] = df['ShoulderRight_Z'] - center['ShoulderRight_Z']\n",
    "    df['Thumb_X'] = df['ThumbRight_X'] - center['ShoulderRight_X']\n",
    "    df['Thumb_Y'] = df['ThumbRight_Y'] - center['ShoulderRight_Y']\n",
    "    df['Thumb_Z'] = df['ThumbRight_Z'] - center['ShoulderRight_Z']\n",
    "    df['ShoulderRef_X'] = df['Shoulder_X']\n",
    "    df['ShoulderRef_Y'] = df['Shoulder_Y']\n",
    "    df['ShoulderRef_Z'] = df['Shoulder_Z']\n",
    "    df['ShoulderOther_X'] = df['ShoulderLeft_X']\n",
    "    df['ShoulderOther_Y'] = df['ShoulderLeft_Y']\n",
    "    df['ShoulderOther_Z'] = df['ShoulderLeft_Z']\n",
    "    center['ShoulderRight_X'] -= center['ShoulderRight_X']\n",
    "    center['ShoulderRight_Y'] -= center['ShoulderRight_Y']\n",
    "    center['ShoulderRight_Z'] -= center['ShoulderRight_Z']\n",
    "else:\n",
    "    df['Wrist_X'] = -(df['WristLeft_X'] - center['ShoulderLeft_X'])\n",
    "    df['Wrist_Y'] = df['WristLeft_Y'] - center['ShoulderLeft_Y']\n",
    "    df['Wrist_Z'] = df['WristLeft_Z'] - center['ShoulderLeft_Z']\n",
    "    df['Hip_X'] = -(df['HipLeft_X'] - center['ShoulderLeft_X'])\n",
    "    df['Hip_Y'] = df['HipLeft_Y'] - center['ShoulderLeft_Y']\n",
    "    df['Hip_Z'] = df['HipLeft_Z'] - center['ShoulderLeft_Z']\n",
    "    df['Elbow_X'] = -(df['ElbowLeft_X'] - center['ShoulderLeft_X'])\n",
    "    df['Elbow_Y'] = df['ElbowLeft_Y'] - center['ShoulderLeft_Y']\n",
    "    df['Elbow_Z'] = df['ElbowLeft_Z'] - center['ShoulderLeft_Z']\n",
    "    df['Hand_X'] = -(df['HandLeft_X'] - center['ShoulderLeft_X'])\n",
    "    df['Hand_Y'] = df['HandLeft_Y'] - center['ShoulderLeft_Y']\n",
    "    df['Hand_Z'] = df['HandLeft_Z'] - center['ShoulderLeft_Z']\n",
    "    df['Shoulder_X'] = -(df['ShoulderLeft_X'] - center['ShoulderLeft_X'])\n",
    "    df['Shoulder_Y'] = df['ShoulderLeft_Y'] - center['ShoulderLeft_Y']\n",
    "    df['Shoulder_Z'] = df['ShoulderLeft_Z'] - center['ShoulderLeft_Z']\n",
    "    df['Thumb_X'] = -(df['ThumbLeft_X'] - center['ShoulderLeft_X'])\n",
    "    df['Thumb_Y'] = df['ThumbLeft_Y'] - center['ShoulderLeft_Y']\n",
    "    df['Thumb_Z'] = df['ThumbLeft_Z'] - center['ShoulderLeft_Z']\n",
    "    df['ShoulderRef_X'] = df['Shoulder_X']\n",
    "    df['ShoulderRef_Y'] = df['Shoulder_Y']\n",
    "    df['ShoulderRef_Z'] = df['Shoulder_Z']\n",
    "    df['ShoulderOther_X'] = df['ShoulderRight_X']\n",
    "    df['ShoulderOther_Y'] = df['ShoulderRight_Y']\n",
    "    df['ShoulderOther_Z'] = df['ShoulderRight_Z']\n",
    "    center['ShoulderLeft_X'] -= center['ShoulderLeft_X']\n",
    "    center['ShoulderLeft_Y'] -= center['ShoulderLeft_Y']\n",
    "    center['ShoulderLeft_Z'] -= center['ShoulderLeft_Z']\n",
    "\n",
    "vectorX = df['Wrist_X'] \n",
    "vectorY = df['Wrist_Y']\n",
    "vectorZ = df['Wrist_Z'] \n",
    "vectors=np.column_stack((vectorX[:-1], vectorY[:-1], vectorZ[:-1]))\n",
    "#find the radius of the spherical distribution\n",
    "magnitudes = np.linalg.norm(vectors, axis=1)\n",
    "largest_magnitude = np.max(magnitudes)\n",
    "avg_magnitude = np.mean(magnitudes)\n",
    "med_magnitude = np.median(magnitudes)\n",
    "radius = largest_magnitude\n",
    "print(radius)\n",
    "print(avg_magnitude)\n",
    "print(med_magnitude)\n",
    "\n",
    "# golden ratio\n",
    "phi = (1 + np.sqrt(5)) / 2\n",
    "\n",
    "# vertices of a unit icosahedron\n",
    "icosahedron_vertices = np.array([\n",
    "    [0, 1, phi],\n",
    "    [0, -1, phi],\n",
    "    [0, 1, -phi],\n",
    "    [0, -1, -phi],\n",
    "    [1, phi, 0],\n",
    "    [-1, phi, 0],\n",
    "    [1, -phi, 0],\n",
    "    [-1, -phi, 0],\n",
    "    [phi, 0, 1],\n",
    "    [-phi, 0, 1],\n",
    "    [phi, 0, -1],\n",
    "    [-phi, 0, -1]\n",
    "])\n",
    "\n",
    "# scaling by the largest magnitude of vector_normalized (from prev calc)\n",
    "factorNorm = radius / phi\n",
    "icosahedron_vertices *= factorNorm\n",
    "\n",
    "    # Assuming icosahedron_vertices and center are defined\n",
    "center = np.array([0, 0, 0])\n",
    "distances = cdist(icosahedron_vertices, icosahedron_vertices)\n",
    "\n",
    "# Find the 5 nearest neighbors for each vertex (excluding itself)\n",
    "# argsort sorts distances, so [:, 1:6] skips the first column (distance to itself) and selects the next 5 nearest neighbors.\n",
    "nearest_neighbors_indices = np.argsort(distances, axis=1)[:, 1:6]\n",
    "# Sort nearest neighbors indices for consistent processing\n",
    "nearest_neighbors_indices = np.sort(nearest_neighbors_indices, axis=1)\n",
    "\n",
    "unique_pyramids_set = set()\n",
    "for vertex_idx, neighbors_idx in enumerate(nearest_neighbors_indices):\n",
    "    vertex = icosahedron_vertices[vertex_idx]\n",
    "    neighbors = icosahedron_vertices[neighbors_idx]\n",
    "\n",
    "    # Generate combinations of neighbors\n",
    "    neighbor_combinations = itertools.combinations(neighbors_idx, 2)\n",
    "\n",
    "    for combination_idx in neighbor_combinations:\n",
    "        combination = icosahedron_vertices[np.array([vertex_idx, *combination_idx])]\n",
    "        combination = combination[np.lexsort(combination.T)]  # Sort vertices of the pyramid\n",
    "\n",
    "        # Calculate distances\n",
    "        dist_01 = np.linalg.norm(combination[0] - combination[1])\n",
    "        dist_12 = np.linalg.norm(combination[1] - combination[2])\n",
    "        dist_20 = np.linalg.norm(combination[2] - combination[0])\n",
    "        \n",
    "        # Check for equilateral triangle\n",
    "        mean_dist = np.mean([dist_01, dist_12, dist_20])\n",
    "        if np.allclose([dist_01, dist_12, dist_20], mean_dist, atol=1e-6):\n",
    "            # Add sorted combination to the set with the center\n",
    "            sorted_indices = tuple(sorted([vertex_idx, *combination_idx]))\n",
    "            unique_pyramids_set.add(sorted_indices)\n",
    "\n",
    "# Convert back to list of pyramids and prepend the center point\n",
    "unique_pyramids = []\n",
    "for indices in unique_pyramids_set:\n",
    "    pyramid_vertices = icosahedron_vertices[list(indices)]\n",
    "    pyramid_with_center = np.vstack([center, pyramid_vertices])  # Add center as the apex\n",
    "    unique_pyramids.append(pyramid_with_center)\n",
    "        \n",
    "print(np.shape(unique_pyramids))\n",
    "array_unique_pyramids = np.array(unique_pyramids)\n",
    "\n",
    "#Prepare bin centers etc just for example calculations down the road - just for show in summary stats\n",
    "wristMotionX = df['Wrist_X'] #flip left X to match right for analysis\n",
    "wristMotionY = df['Wrist_Y']\n",
    "wristMotionZ = df['Wrist_Z']\n",
    "    \n",
    "wristMotionOnly=np.column_stack((wristMotionX, wristMotionY, wristMotionZ))\n",
    "n_bins = 3\n",
    "xb, bin_limits, bin_centers = fixing_bin_center(wristMotionOnly, n_bins, center, right)\n",
    "\n",
    "#outsideCI_perzone = outsideCI_perzone.flatten().astype(int)\n",
    "title = 'Flagged Participants Probabilities'\n",
    "colorbar_title = '# participants outside CI'\n",
    "plot3dIcosahedron(heatDifference_icosahedron[-20:], title, colorbar_title, array_unique_pyramids, nt_ci_data, 0, heatDifference_icosahedron[:20])\n",
    "plot3dIcosahedron(heatDifference_icosahedron[:20], title, colorbar_title, array_unique_pyramids/2, nt_ci_data, 1, heatDifference_icosahedron[-20:])\n",
    "\n",
    "\n",
    "plot3dDust(df, 'Sample Neurotypical Wrist Position Data',right)\n",
    "\n",
    "plot3dRectilinear(stroke_diff_df, Rect_nt_ci_data, 'Rectilinear Model Data')\n",
    "\n",
    "# Make a grid that shows the average percentage in each zone - organize not by number but by relation to each other- Superior/Poster\n",
    "#plot3dIcosahedron_towers(outsideCI_perzone, title, colorbar_title, array_unique_pyramids, heatmap_plot)\n",
    "\n",
    "jointAngles = calc_jointangles(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
